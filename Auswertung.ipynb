{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5769fb6",
   "metadata": {},
   "source": [
    "# Auswertung der Mobbing-Umfrage\n",
    "\n",
    "Dieses Notebook dient der automatisierten Auswertung der Ergebnisse des Fragebogens \"Schulklima, Mobbing und Gewalt\" (SV der WSP). Es verarbeitet die Daten aus Ihrer CSV-Datei, die Sie zuvor aus Tally exportiert haben.\n",
    "\n",
    "## Funktionsweise\n",
    "\n",
    "1. **Datenimport**: Das Notebook liest die CSV-Datei ein und bereitet die Daten f√ºr die Analyse vor.\n",
    "2. **Datenanalyse**: Es werden Muster und Trends im Antwortverhalten der Sch√ºlerinnen und Sch√ºler untersucht.\n",
    "3. **Visualisierung**: Die Ergebnisse werden durch anschauliche Diagramme und Grafiken dargestellt.\n",
    "4. **Berichtserstellung**: Abschlie√üend wird ein umfassender PDF-Bericht generiert, der alle wichtigen Erkenntnisse zusammenfasst.\n",
    "\n",
    "## Anleitung\n",
    "\n",
    "_Achtung_: Werfen Sie vor dem Start einen Blick in die Tabelle, um bspw. Namen in Antworten zu anonymisieren. Stellen Sie sicher, dass die Datei als Trennzeichen \"Komma\" verwendet.\n",
    "\n",
    "Um die Auswertung zu starten, f√ºhren Sie \"Run All\" aus. Sie werden aufgefordert, den Autorennamen, das SJ, das Berichtsdatum und die Anzahl aller Sch√ºlerInnen einzugeben. Etwas weiter unten werden Sie gebeten, die Datei mit den Umfrageergebnissen hochzuladen. Daraufhin k√∂nnen Sie au√üerdem den PDF-Bericht des Vorjahres sowie die Ergebnisse einer Meta-Umfrage hochladen, um Vergleiche zu erm√∂glichen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85093ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Input Author Name and Student Count\n",
    "from datetime import datetime\n",
    "\n",
    "# Determine school year based on current date\n",
    "current_year = datetime.now().year\n",
    "if datetime.now().month >= 7:  # If it's July or later\n",
    "    school_year = f\"{current_year}/{current_year + 1}\"\n",
    "else:  # If it's before July\n",
    "    school_year = f\"{current_year - 1}/{current_year}\"\n",
    "\n",
    "\n",
    "author_name = input(\"Bitte geben Sie den Autorennanmen ein, der auf dem Bericht erscheinen soll, oder dr√ºcken Sie Enter f√ºr keinen Autor: \") or \" \"\n",
    "school_year = input(f\"Bitte geben Sie das aktuelle Schuljahr ein, oder dr√ºcken Sie Enter f√ºr das ermittelte aktuelle Schuljahr {school_year}: \") or school_year\n",
    "date_today = input(f\"Bitte geben Sie das Datum des Berichts ein, oder dr√ºcken Sie Enter f√ºr das heutige Datum {datetime.now().strftime('%d.%m.%Y')}: \") or datetime.now().strftime('%d.%m.%Y')\n",
    "student_count = int(input(\"Bitte geben Sie die Gesamtanzahl der Sch√ºler*innen in Ihrer Schule ein, oder dr√ºcken Sie Enter f√ºr keine Angabe: \") or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9efa2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Datei-Upload: Ergebnisse.csv\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from IPython.display import clear_output, display, Javascript\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# 1. Check: Are we running in Colab?\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# 2. File check & upload logic\n",
    "required_file = 'Ergebnisse.csv'\n",
    "\n",
    "# Ensure we define specific anchor for the title if you want to jump to the top\n",
    "# You can add a markdown cell above this code with: # <a id=\"upload_section\"></a>\n",
    "# Then use: display(Javascript('document.getElementById(\"upload_section\").scrollIntoView()'))\n",
    "\n",
    "if not os.path.exists(required_file):\n",
    "    print(f\"‚ö†Ô∏è Datei '{required_file}' fehlt!\")\n",
    "    \n",
    "    # --- CASE A: Google Colab ---\n",
    "    if IN_COLAB:\n",
    "        print(\"Bitte laden Sie die Datei jetzt hoch (Dialog √∂ffnet sich unten):\")\n",
    "        \n",
    "        uploaded = files.upload() # Pauses the script until upload is complete\n",
    "        \n",
    "        for fn in uploaded.keys():\n",
    "            if fn != required_file:\n",
    "                os.rename(fn, required_file)\n",
    "                print(f\"Datei wurde in '{required_file}' umbenannt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1342f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datei 'Ergebnisse.csv' bereits vorhanden. Gehe weiter...\n"
     ]
    }
   ],
   "source": [
    "#@title Datei-Upload: Ergebnisse.csv (Fortsetzung)\n",
    "\n",
    "if not os.path.exists(required_file):\n",
    "    if not IN_COLAB:\n",
    "        print(\"Lokalmodus erkannt.\")\n",
    "        print(f\"Bitte legen Sie die Datei '{required_file}' in denselben Ordner wie dieses Notebook.\")\n",
    "        \n",
    "        # Optional: An upload button for local use (requires ipywidgets)\n",
    "        print(\"Alternativ: Datei hier ausw√§hlen:\")\n",
    "        uploader = widgets.FileUpload(accept='.csv', multiple=False)\n",
    "        display(uploader)\n",
    "        \n",
    "        # Wait for manual user action (loop)\n",
    "        print(\"Warte auf Datei...\")\n",
    "        while not os.path.exists(required_file):\n",
    "            # Check if widget was used\n",
    "            if uploader.value:\n",
    "                # Save file from widget\n",
    "                # (Syntax for ipywidgets >= 8.0)\n",
    "                if isinstance(uploader.value, tuple): # Old version\n",
    "                     content = uploader.value[0]['content']\n",
    "                     filename = uploader.value[0]['name']\n",
    "                else: # New version (more likely in VSCode)\n",
    "                     vals = list(uploader.value) # Gets the first element\n",
    "                     content = vals[0]['content']\n",
    "                     filename = vals[0]['name']\n",
    "\n",
    "                with open(required_file, 'wb') as f:\n",
    "                    f.write(content)\n",
    "                print(f\"Upload via Widget erfolgreich: {filename}\")\n",
    "                break\n",
    "                \n",
    "            time.sleep(1) # Wait briefly to save CPU\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"‚úÖ Datei '{required_file}' gefunden. Analyse l√§uft weiter...\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚úÖ Datei '{required_file}' bereits vorhanden. Gehe weiter...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad9152d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lokale Umgebung erkannt. Suche nach PDF-Dateien im aktuellen Ordner...\n",
      "\n",
      "‚ÑπÔ∏è Keine historischen Daten gefunden. (Start bei Null)\n"
     ]
    }
   ],
   "source": [
    "#@title Historische Daten aus alten Berichten laden\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "history_data = []\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"--- üì§ Upload Vorjahres-Bericht ---\")\n",
    "    print(\"Bitte laden Sie den PDF-Bericht des LETZTEN Jahres hoch.\")\n",
    "    print(\"(Da dieser alle vorherigen Jahre enth√§lt, reicht die aktuellste Datei.)\")\n",
    "    print(\"Falls dies das allererste Jahr ist: Einfach abbrechen / nichts hochladen.\")\n",
    "    uploaded_pdfs = files.upload()\n",
    "else:\n",
    "    print(\"Lokale Umgebung erkannt. Suche nach PDF-Dateien im aktuellen Ordner...\")\n",
    "\n",
    "# 2. Alle PDFs verarbeiten\n",
    "pdf_files = glob.glob(\"*.pdf\")\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        with open(pdf_file, 'rb') as f:\n",
    "            content = f.read()\n",
    "            # Wir suchen das LETZTE g√ºltige JSON-Objekt am Ende der Datei (letzte 250 kB)\n",
    "            search_window = content[-250000:]\n",
    "            parts = search_window.split(b'\\n')\n",
    "            \n",
    "            found_json = False\n",
    "            for part in reversed(parts):\n",
    "                if not part.strip(): continue\n",
    "                try:\n",
    "                    data = json.loads(part)\n",
    "                    \n",
    "                    # A) Es ist eine Liste (Das ist ein Master-Archiv)\n",
    "                    if isinstance(data, list):\n",
    "                        # Logik: Wir nehmen immer das Archiv, das am MEISTEN Jahre enth√§lt.\n",
    "                        if len(data) > len(history_data):\n",
    "                            history_data = data\n",
    "                            print(f\"‚úÖ Master-Archiv geladen aus: {pdf_file} (Enth√§lt {len(data)} Jahre)\")\n",
    "                        found_json = True\n",
    "                        break\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Fehler beim Lesen von {pdf_file}: {e}\")\n",
    "\n",
    "# WICHTIG: Nach Schuljahr sortieren\n",
    "history_data.sort(key=lambda x: x['meta']['school_year'])\n",
    "\n",
    "if history_data:\n",
    "    # Wir nehmen das letzte Jahr aus der Historie, um dem User zu zeigen, wo wir stehen\n",
    "    latest_year = history_data[-1]['meta']['school_year']\n",
    "    print(f\"\\nüìà Historie erfolgreich eingelesen!\")\n",
    "    print(f\"   Stand: {len(history_data)} Datens√§tze vorhanden.\")\n",
    "    print(f\"   Letztes vorhandenes Jahr: {latest_year}\")\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è Keine historischen Daten gefunden. (Start bei Null)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66504134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feedback-Daten gefunden. Werden in Anhang C integriert.\n"
     ]
    }
   ],
   "source": [
    "#@title Datei-Upload: Feedback.csv (Optional)\n",
    "required_feedback_file = 'Feedback.csv'\n",
    "\n",
    "if not os.path.exists(required_feedback_file):\n",
    "    if IN_COLAB:\n",
    "        print(\"Optional: Laden Sie 'Feedback.csv' hoch, falls vorhanden.\")\n",
    "        print(\"Falls nicht, wird dieser Teil im Bericht √ºbersprungen.\")\n",
    "        uploaded_fb = files.upload()\n",
    "        for fn in uploaded_fb.keys():\n",
    "            if fn != required_feedback_file:\n",
    "                os.rename(fn, required_feedback_file)\n",
    "    else:\n",
    "        print(f\"Lokalmodus: Suche nach '{required_feedback_file}'...\")\n",
    "\n",
    "if os.path.exists(required_feedback_file):\n",
    "    print(\"‚úÖ Feedback-Daten gefunden. Werden in Anhang C integriert.\")\n",
    "    has_feedback = True\n",
    "    df_feedback = pd.read_csv(required_feedback_file)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Keine Feedback-Daten. Anhang C wird ausgeblendet.\")\n",
    "    has_feedback = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment detected. Please ensure Pandoc and XeTeX are installed manually if needed.\n",
      "pypandoc already installed.\n",
      "tabulate already installed.\n",
      "seaborn already installed.\n",
      "matplotlib already installed.\n",
      "matplotlib-venn already installed.\n"
     ]
    }
   ],
   "source": [
    "#@title Installation of Dependencies (Colab vs. Local)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Colab erkannt. Installiere Systemabh√§ngigkeiten (Pandoc, XeTeX)... Dies kann einige Minuten dauern.\")\n",
    "    # Run shell commands using the ! magic syntax\n",
    "    # The print statement must be on a new line, not appended to the shell command\n",
    "    !sudo apt-get install -y pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null 2>&1 || (echo \"Paketlisten veraltet, f√ºhre Update durch...\" && sudo apt-get update -qq && sudo apt-get install -y pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null)\n",
    "    print(\"Systemabh√§ngigkeiten installiert.\")\n",
    "\n",
    "else:\n",
    "    print(\"Lokale Umgebung erkannt. Bitte stellen Sie sicher, dass Pandoc und XeTeX bei Bedarf manuell installiert sind.\")\n",
    "\n",
    "# 3. Check if pypandoc (Python lib) is missing\n",
    "try:\n",
    "    import pypandoc\n",
    "    print(\"pypandoc already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing pypandoc...\")\n",
    "    %pip install pypandoc\n",
    "\n",
    "try:\n",
    "    import tabulate\n",
    "    print(\"tabulate already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing tabulate...\")\n",
    "    %pip install tabulate\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    print(\"seaborn already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing seaborn...\")\n",
    "    %pip install seaborn\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"matplotlib already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing matplotlib...\")\n",
    "    %pip install matplotlib\n",
    "\n",
    "try:\n",
    "    import matplotlib_venn\n",
    "    print(\"matplotlib-venn already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing matplotlib-venn...\")\n",
    "    %pip install matplotlib-venn\n",
    "\n",
    "try:\n",
    "    import PIL\n",
    "    print(\"PIL already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing Pillow...\")\n",
    "    %pip install Pillow\n",
    "\n",
    "\n",
    "if os.path.exists(\"img\"):\n",
    "    shutil.rmtree(\"img\")  # Remove the directory and all its contents\n",
    "os.makedirs(\"img\", exist_ok=True)  # Recreate the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26cb5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Results CSV\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('Ergebnisse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc3d4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Datenbereinigung: Unplausible Antworten markieren\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_survey_data(df):\n",
    "    \"\"\"\n",
    "    Markiert unplausible Antworten vorsichtig.\n",
    "    L√∂scht keine Daten, sondern f√ºgt eine Spalte 'is_suspicious' und 'suspicion_reason' hinzu.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Mapping der Text-Antworten in Zahlen f√ºr die Analyse\n",
    "    # Frequenz-Skalen (Fragen 15, 18, 21) [cite: 66-75]\n",
    "    freq_map = {\n",
    "        'Nie': 0,\n",
    "        'Selten': 1,\n",
    "        'Monatlich': 2,\n",
    "        'W√∂chentlich': 3,\n",
    "        'Mehrmals pro Woche': 4,\n",
    "        'T√§glich': 5\n",
    "    }\n",
    "    \n",
    "    # Likert-Skalen sind im CSV meist schon 1-5, falls nicht, hier mappen.\n",
    "    # Wir gehen davon aus, dass Likert-Fragen (Q3-14, Q36-39) numerisch 1-5 vorliegen.\n",
    "    \n",
    "    # Arbeitskopie erstellen\n",
    "    df_check = df.copy()\n",
    "    \n",
    "    # Frequenz-Spalten umwandeln (Q15=Physisch, Q18=Verbal, Q21=Cyber)\n",
    "    violence_cols = ['Q15', 'Q18', 'Q21']\n",
    "    for col in violence_cols:\n",
    "        if col in df_check.columns:\n",
    "            df_check[f'{col}_num'] = df_check[col].map(freq_map).fillna(0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # FILTER 1: Extremes Straight-Lining (Konservativ)\n",
    "    # ---------------------------------------------------------\n",
    "    # Wir pr√ºfen nur die Matrix-Fragen zum Klima/Lehrer/Familie (Likert 1-5)\n",
    "    # Fragen 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 36, 37, 38, 39\n",
    "    likert_cols = [\n",
    "        'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', \n",
    "        'Q11', 'Q12', 'Q13', 'Q14', 'Q36', 'Q37', 'Q38', 'Q39'\n",
    "    ]\n",
    "    \n",
    "    # Nur Spalten nutzen, die auch im Datensatz existieren\n",
    "    existing_likert = [c for c in likert_cols if c in df_check.columns]\n",
    "    \n",
    "    suspicious_indices = []\n",
    "    reasons = {}\n",
    "\n",
    "    if existing_likert:\n",
    "        # Berechne Standardabweichung pro Zeile\n",
    "        std_devs = df_check[existing_likert].std(axis=1)\n",
    "        \n",
    "        # Kriterium: Standardabweichung ist exakt 0 (hat √ºberall exakt das gleiche geklickt)\n",
    "        # UND es wurden mehr als 5 Fragen beantwortet (um NaNs abzufangen)\n",
    "        count_answers = df_check[existing_likert].count(axis=1)\n",
    "        \n",
    "        straight_liners = df_check[(std_devs == 0) & (count_answers > 10)].index\n",
    "        \n",
    "        for idx in straight_liners:\n",
    "            suspicious_indices.append(idx)\n",
    "            reasons[idx] = \"Straight-Lining (Identische Antwort √ºberall)\"\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # FILTER 2: Harter Logik-Widerspruch (Sicherheit vs. Gewalt)\n",
    "    # ---------------------------------------------------------\n",
    "    # Logik: Wer Q6 (Sicher) mit 5 bewertet, aber Q15 (Physische Gewalt) mit >= 4 (oft)\n",
    "    \n",
    "    if 'Q6' in df_check.columns and 'Q15_num' in df_check.columns:\n",
    "        # Q6 = 5 (\"Stimmt voll und ganz\") \n",
    "        # Q15_num >= 4 (\"Mehrmals pro Woche\" oder \"T√§glich\") [cite: 74, 75]\n",
    "        contradiction = df_check[\n",
    "            (df_check['Q6'] == 5) & \n",
    "            (df_check['Q15_num'] >= 4)\n",
    "        ].index\n",
    "        \n",
    "        for idx in contradiction:\n",
    "            suspicious_indices.append(idx)\n",
    "            current_reason = reasons.get(idx, \"\")\n",
    "            new_reason = \"Widerspruch: F√ºhlt sich sicher (5) aber t√§gliche Gewalt\"\n",
    "            reasons[idx] = (current_reason + \"; \" + new_reason).strip(\"; \")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Ergebnis zusammenf√ºgen\n",
    "    # ---------------------------------------------------------\n",
    "    df['is_suspicious'] = False\n",
    "    df['suspicion_reason'] = \"\"\n",
    "    \n",
    "    # Markiere die gefundenen Indizes\n",
    "    if suspicious_indices:\n",
    "        df.loc[suspicious_indices, 'is_suspicious'] = True\n",
    "        # Setze die Gr√ºnde\n",
    "        for idx, reason in reasons.items():\n",
    "            df.loc[idx, 'suspicion_reason'] = reason\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Beispiel zur Nutzung ---\n",
    "# Angenommen, 'data' ist dein DataFrame aus der CSV/Excel\n",
    "# cleaned_data = clean_survey_data(data)\n",
    "\n",
    "# Filtern (optional, wenn du sie rauswerfen willst):\n",
    "# final_data = cleaned_data[cleaned_data['is_suspicious'] == False]\n",
    "\n",
    "df = clean_survey_data(df)\n",
    "\n",
    "# Print number of suspicious entries found\n",
    "num_suspicious = df['is_suspicious'].sum()\n",
    "\n",
    "df = df[df['is_suspicious'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dc6a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Survey Format\n",
    "survey = [\n",
    "    {\n",
    "      \"short_id\": \"Submitted at\",\n",
    "      \"long_question\": \"Timestamp\",\n",
    "      \"type\": \"datetime\"\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"class_level\",\n",
    "      \"long_question\": \"In welcher Klasse bist du?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"5. Klasse\",\n",
    "        \"6. Klasse\",\n",
    "        \"7. Klasse\",\n",
    "        \"8. Klasse\",\n",
    "        \"9. Klasse\",\n",
    "        \"10. Klasse\",\n",
    "        \"11. Klasse\",\n",
    "        \"12. Klasse\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"gender\",\n",
    "      \"long_question\": \"Wie bezeichnest du dein Geschlecht?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"weiblich\",\n",
    "        \"m√§nnlich\",\n",
    "        \"divers\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"friends_in_class\",\n",
    "      \"long_question\": \"In meiner Klasse habe ich enge FreundInnen, auf die ich mich verlassen kann.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"respect_in_class\",\n",
    "      \"long_question\": \"In meiner Klasse gehen wir h√∂flich und respektvoll miteinander um.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"liked_by_others\",\n",
    "      \"long_question\": \"Ich habe das Gef√ºhl, dass die anderen in der Klasse es m√∂gen, wenn ich dabei bin.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"safety_in_class\",\n",
    "      \"long_question\": \"Ich f√ºhle mich in meiner Klasse sicher.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"like_school\",\n",
    "      \"long_question\": \"Ich gehe gerne zur Schule.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"teacher_fairness\",\n",
    "      \"long_question\": \"Ich habe das Gef√ºhl, dass die meisten Lehrkr√§fte uns Sch√ºlerInnen gerecht behandeln.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"teacher_trust\",\n",
    "      \"long_question\": \"Es gibt Lehrkr√§fte in der Schule, denen ich vertrauen kann.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"teacher_care\",\n",
    "      \"long_question\": \"Ich habe das Gef√ºhl, dass die Lehrkr√§fte meine Sorgen ernst nehmen.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"adult_listener_home\",\n",
    "      \"long_question\": \"Zu Hause gibt es mindestens eine erwachsene Person, die mir zuh√∂rt, wenn es mir nicht gut geht.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"family_acceptance\",\n",
    "      \"long_question\": \"In meiner Familie habe ich das Gef√ºhl, so akzeptiert zu werden, wie ich bin.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"friends_outside_school\",\n",
    "      \"long_question\": \"Ich habe mindestens eine gute Freundin oder einen guten Freund au√üerhalb meiner Klasse, der/dem ich vertraue.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"reliable_people_general\",\n",
    "      \"long_question\": \"Insgesamt habe ich das Gef√ºhl, dass ich Menschen habe, auf die ich mich wirklich verlassen kann.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"physical_violence_freq\",\n",
    "      \"long_question\": \"Wie oft wurdest du in den letzten 6 Monaten Opfer von k√∂rperlicher Gewalt von Mitsch√ºlerInnen (z. B. Schubsen, Schlagen, Treten)\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Nie\",\n",
    "        \"Selten\",\n",
    "        \"Monatlich\",\n",
    "        \"W√∂chentlich\",\n",
    "        \"Mehrmals pro Woche\",\n",
    "        \"T√§glich\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"physical_violence_type\",\n",
    "      \"long_question\": \"In welcher Form ist das passiert? (K√∂rperliche Gewalt)\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"hit_kicked\", \"long\": \"Ich wurde geschlagen oder getreten.\" },\n",
    "        { \"short_id\": \"threatened\", \"long\": \"Ich wurde bedroht (z. B. mit Schl√§gen oder Gegenst√§nden).\" },\n",
    "        { \"short_id\": \"restrained\", \"long\": \"Man hat mich festgehalten oder am Weggehen gehindert.\" },\n",
    "        { \"short_id\": \"property_damage\", \"long\": \"Mitsch√ºlerInnen haben meine Sachen besch√§digt oder versteckt.\" },\n",
    "        { \"short_id\": \"extortion\", \"long\": \"Ich wurde erpresst.\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"physical_violence_duration\",\n",
    "      \"long_question\": \"Seit wann passiert das? (K√∂rperliche Gewalt)\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Mehr als 2 Jahre\",\n",
    "        \"1-2 Jahre\",\n",
    "        \"6-12 Monate\",\n",
    "        \"3-6 Monate\",\n",
    "        \"1-3 Monate\",\n",
    "        \"Weniger als 1 Monat\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"verbal_violence_freq\",\n",
    "      \"long_question\": \"Wie oft wurdest du in den letzten 6 Monaten Opfer von verbaler oder sozialer Gewalt von Mitsch√ºlerInnen? (z. B. Beschimpfungen, Ausgrenzen, Ger√ºchte)\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Nie\",\n",
    "        \"Selten\",\n",
    "        \"Monatlich\",\n",
    "        \"W√∂chentlich\",\n",
    "        \"Mehrmals pro Woche\",\n",
    "        \"T√§glich\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"verbal_violence_type\",\n",
    "      \"long_question\": \"In welcher Form ist das passiert? (Verbale/Soziale Gewalt)\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"insults\", \"long\": \"Beleidigungen oder Schimpfw√∂rter\" },\n",
    "        { \"short_id\": \"nicknames\", \"long\": \"Gemeine Spitznamen\" },\n",
    "        { \"short_id\": \"mockery\", \"long\": \"Ausgelacht oder verspottet werden\" },\n",
    "        { \"short_id\": \"rumors\", \"long\": \"Ger√ºchte oder L√ºgen verbreitet\" },\n",
    "        { \"short_id\": \"exclusion\", \"long\": \"Ignoriert oder bewusst ausgeschlossen werden\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"verbal_violence_duration\",\n",
    "      \"long_question\": \"Seit wann passiert das? (Verbale/Soziale Gewalt)\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Mehr als 2 Jahre\",\n",
    "        \"1-2 Jahre\",\n",
    "        \"6-12 Monate\",\n",
    "        \"3-6 Monate\",\n",
    "        \"1-3 Monate\",\n",
    "        \"Weniger als 1 Monat\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"cyberbullying_freq\",\n",
    "      \"long_question\": \"Wie oft wurdest du in den letzten 6 Monaten Opfer von Cybermobbing von Mitsch√ºlerInnen (z. B. Beleidigungen, Blo√üstellung oder Bedrohung online)\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Nie\",\n",
    "        \"Selten\",\n",
    "        \"Monatlich\",\n",
    "        \"W√∂chentlich\",\n",
    "        \"Mehrmals pro Woche\",\n",
    "        \"T√§glich\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"cyberbullying_type\",\n",
    "      \"long_question\": \"In welcher Form ist das passiert? (Cybermobbing)\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"insults_chat\", \"long\": \"Beleidigungen per Chat oder Kommentar\" },\n",
    "        { \"short_id\": \"rumors_online\", \"long\": \"Ger√ºchte oder L√ºgen √ºber mich wurden online verbreitet\" },\n",
    "        { \"short_id\": \"embarrassing_media\", \"long\": \"Peinliche Fotos/Videos von mir wurden ver√∂ffentlicht\" },\n",
    "        { \"short_id\": \"threats_online\", \"long\": \"Bedrohung oder Erpressung per Chat/SMS/Web\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"victim_confirmation_check\",\n",
    "      \"long_question\": \"Nein, ich war in den letzten 6 Monaten *kein* Opfer von k√∂rperlicher oder verbaler Gewalt oder Cybermobbing\",\n",
    "      \"type\": \"checkbox\",\n",
    "      \"options\": []\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"perpetrator_count\",\n",
    "      \"long_question\": \"Wie viele Personen waren an diesen Handlungen von k√∂rperlicher Gewalt, verbaler Gewalt oder Cybermobbing gegen dich meistens beteiligt?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Eine Person\",\n",
    "        \"Zwei bis vier Personen\",\n",
    "        \"Mehr als vier Personen\",\n",
    "        \"Mehr als die H√§lfte einer Klasse\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"perpetrators_classmate\",\n",
    "      \"long_question\": \"Sind diese Personen aus deiner Klasse?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Ja\",\n",
    "        \"Nein\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"defense_reaction\",\n",
    "      \"long_question\": \"Wie wehrst du dich gegen k√∂rperliche oder andere Formen von Gewalt / Cybermobbing?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"physical\", \"long\": \"K√∂rperlich (Zur√ºckschlagen, Pr√ºgel)\" },\n",
    "        { \"short_id\": \"verbal\", \"long\": \"Verbal (Beleidigungen, Rufe)\" },\n",
    "        { \"short_id\": \"friends\", \"long\": \"Ich hole FreundInnen.\" },\n",
    "        { \"short_id\": \"teachers\", \"long\": \"Ich hole LehrerInnen.\" },\n",
    "        { \"short_id\": \"withdrawal\", \"long\": \"Ich ziehe mich zur√ºck/ gehe weg.\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"observed_bullying_freq\",\n",
    "      \"long_question\": \"Wie oft hast du Mobbing an anderen Mitsch√ºlerInnen beobachtet?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Nie\",\n",
    "        \"Selten\",\n",
    "        \"Monatlich\",\n",
    "        \"W√∂chentlich\",\n",
    "        \"Mehrmals pro Woche\",\n",
    "        \"T√§glich\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"bullying_location\",\n",
    "      \"long_question\": \"Wo passieren √úbergriffe oder Mobbing / wo siehst du sie?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"none_observed\", \"long\": \"Ich habe keine √úbergriffe beobachtet\" },\n",
    "        { \"short_id\": \"classroom\", \"long\": \"Klassenzimmer\" },\n",
    "        { \"short_id\": \"schoolyard\", \"long\": \"Schulhof\" },\n",
    "        { \"short_id\": \"hallway\", \"long\": \"Treppenhaus/Flur\" },\n",
    "        { \"short_id\": \"restrooms\", \"long\": \"Toiletten\" },\n",
    "        { \"short_id\": \"way_to_school\", \"long\": \"Schulweg\" },\n",
    "        { \"short_id\": \"online\", \"long\": \"Online\" },\n",
    "        { \"short_id\": \"elsewhere\", \"long\": \"Anderswo\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"bullying_time\",\n",
    "      \"long_question\": \"Wann passieren solche √úbergriffe / wann siehst du sie?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"during_class\", \"long\": \"W√§hrend des Unterrichts\" },\n",
    "        { \"short_id\": \"during_breaks\", \"long\": \"In den Pausen\" },\n",
    "        { \"short_id\": \"before_after_school\", \"long\": \"Vor oder nach der Schule\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"intervention_willingness\",\n",
    "      \"long_question\": \"Wenn du sehen w√ºrdest, dass jemand gemobbt wird, w√ºrdest du selbst eingreifen oder helfen?\",\n",
    "      \"type\": \"likert\",\n",
    "      \"options\": [\"1 (Gar nicht) bis 5 (Auf jeden Fall)\"]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"observer_feelings\",\n",
    "      \"long_question\": \"Wenn du Mobbing beobachtest, was f√ºhlst oder denkst du dabei?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"disapproval\", \"long\": \"‚ÄûDas ist nicht in Ordnung.‚Äú\" },\n",
    "        { \"short_id\": \"fear_of_retaliation\", \"long\": \"‚ÄûDas Opfer tut mir leid, aber ich habe Angst, selbst gemobbt zu werden.‚Äú\" },\n",
    "        { \"short_id\": \"helplessness\", \"long\": \"‚ÄûIch w√ºrde gerne helfen, wei√ü aber nicht wie.‚Äú\" },\n",
    "        { \"short_id\": \"support_side\", \"long\": \"‚ÄûIch will eine der beiden Seiten unterst√ºtzen.‚Äú\" },\n",
    "        { \"short_id\": \"indifference\", \"long\": \"‚ÄûEs ist mir egal.‚Äú\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"past_reaction_observation\",\n",
    "      \"long_question\": \"Wie hast du in der Vergangenheit reagiert, wenn du Mobbing gesehen hast?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"joined_in\", \"long\": \"Ich habe beim Mobben mitgemacht.\" },\n",
    "        { \"short_id\": \"looked_away\", \"long\": \"Ich habe weggeschaut, um √Ñrger zu vermeiden.\" },\n",
    "        { \"short_id\": \"watched_passively\", \"long\": \"Ich habe zugeschaut, ohne einzugreifen.\" },\n",
    "        { \"short_id\": \"got_help\", \"long\": \"Ich habe eine andere Person dazugeholt.\" },\n",
    "        { \"short_id\": \"helped_directly\", \"long\": \"Ich habe versucht, dem Opfer direkt zu helfen.\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"knows_help_contact\",\n",
    "      \"long_question\": \"Ich wei√ü, an wen ich mich wenden kann, wenn ich gemobbt werde oder Probleme in der Klasse habe.\",\n",
    "      \"type\": \"binary\",\n",
    "      \"options\": [\n",
    "        \"Ja\",\n",
    "        \"Nein\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"preferred_help_contact\",\n",
    "      \"long_question\": \"An wen w√ºrdest du dich wenden?\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"counselor\", \"long\": \"VertrauenslehrerIn\" },\n",
    "        { \"short_id\": \"class_teacher\", \"long\": \"KlassenlehrerIn\" },\n",
    "        { \"short_id\": \"friends\", \"long\": \"FreundInnen\" },\n",
    "        { \"short_id\": \"family\", \"long\": \"Eltern / Familie\" },\n",
    "        { \"short_id\": \"helpline\", \"long\": \"Kinder- und Jugendtelefon\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Andere\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"bullying_motives_perception\",\n",
    "      \"long_question\": \"Warum denkst du, mobben manche Sch√ºlerInnen andere? (Mehrfachauswahl)\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"money_material\", \"long\": \"Geld oder materielle Dinge\" },\n",
    "        { \"short_id\": \"clothing\", \"long\": \"Kleidung\" },\n",
    "        { \"short_id\": \"appearance\", \"long\": \"Aussehen / K√∂rperform\" },\n",
    "        { \"short_id\": \"behavior\", \"long\": \"Verhalten\" },\n",
    "        { \"short_id\": \"rivalry\", \"long\": \"Rivalit√§t / Konkurrenz\" },\n",
    "        { \"short_id\": \"background_religion\", \"long\": \"Herkunft / Religion / Hautfarbe\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Anderes\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"teachers_notice_bullying\",\n",
    "      \"long_question\": \"Die LehrerInnen bemerken es, wenn Mobbing oder Streit passiert.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"teachers_intervene_bullying\",\n",
    "      \"long_question\": \"Die LehrerInnen greifen ein, wenn sie merken, dass Sch√ºlerInnen gemobbt werden.\",\n",
    "      \"type\": \"likert\",\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"students_help_each_other\",\n",
    "      \"long_question\": \"Die meisten Mitsch√ºlerInnen helfen einander, wenn Streit oder Mobbing passiert.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"school_community_support\",\n",
    "      \"long_question\": \"Ich f√ºhle mich von der Schulgemeinschaft (LehrerInnen und Sch√ºlerInnen) unterst√ºtzt, wenn ich Probleme habe.\",\n",
    "      \"type\": \"likert\",\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"own_bullying_behavior\",\n",
    "      \"long_question\": \"Wie oft warst du in den letzten Monaten daran beteiligt, andere Sch√ºlerInnen in deiner Schule zu √§rgern oder anzugreifen?\",\n",
    "      \"type\": \"single_choice\",\n",
    "      \"options\": [\n",
    "        \"Nie\",\n",
    "        \"Einmal\",\n",
    "        \"Mehrfach im letzten Monat\",\n",
    "        \"Ungef√§hr einmal pro Woche\",\n",
    "        \"Mehrmals pro Woche\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"reason_for_own_behavior\",\n",
    "      \"long_question\": \"Warum hast du das getan? (Mehrfachauswahl)\",\n",
    "      \"type\": \"multiple_choice\",\n",
    "      \"options\": [\n",
    "        { \"short_id\": \"anger\", \"long\": \"Aus Wut\" },\n",
    "        { \"short_id\": \"distress\", \"long\": \"Aus Not\" },\n",
    "        { \"short_id\": \"fun\", \"long\": \"Aus Spa√ü\" },\n",
    "        { \"short_id\": \"retaliation\", \"long\": \"Weil ich selbst ge√§rgert wurde\" },\n",
    "        { \"short_id\": \"other\", \"long\": \"Sonstiges\" }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"short_id\": \"open_feedback_text\",\n",
    "      \"long_question\": \"Hier kannst du weitere Gedanken oder Erfahrungen zu Konflikten, Mobbing oder Gewalt mitteilen.\",\n",
    "      \"type\": \"textarea\",\n",
    "      \"options\": []\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Markdown Template for Evaluation\n",
    "\n",
    "template = r\"\"\"\n",
    "---\n",
    "title: \"Statusbericht: Schulklima & Gewaltpr√§vention\"\n",
    "subtitle: \"Statistische Auswertung und Risikoanalyse - Schuljahr {school_year}\"\n",
    "author: \"{author}\"\n",
    "date: \"{date_today}\"\n",
    "lang: de\n",
    "geometry: margin=2.5cm\n",
    "paper: a4\n",
    "toc: true\n",
    "header-includes:\n",
    "  - \\usepackage{{booktabs}}\n",
    "  - \\usepackage{{graphicx}}\n",
    "  - \\usepackage{{xcolor}}\n",
    "  - \\usepackage{longtable}\n",
    "  - \\usepackage{array}\n",
    "  - \\usepackage{float}\n",
    "  - \\usepackage[section]{placeins}\n",
    "---\n",
    "\n",
    "{ai_abstract_section}\n",
    "\n",
    "# 1. Einleitung und Datenbasis\n",
    "\n",
    "Dieser Bericht fasst die Ergebnisse der anonymen Erhebung zum Thema Schulklima zusammen. Die Datengrundlage bildet der standardisierte \"Fragebogen ‚Äì Schulklima, Mobbing und Gewalt\" von der SV der Waldorfschule Potsdam (JMG, 2025).\n",
    "\n",
    "**Eckdaten der Erhebung:**\n",
    "\n",
    "* **Erhebungszeitraum:** {data_collection_period}\n",
    "* **Teilnehmende:** Insgesamt haben **{n_overall}** Sch√ºlerinnen und Sch√ºler an der Befragung teilgenommen.\n",
    "* **G√ºltige Antworten:** Nach Datenbereinigung verbleiben **{n_total}** verwertbare Datens√§tze. {n_suspicious} Datens√§tze wurden als unplausibel markiert und ausgeschlossen.\n",
    "* **R√ºcklaufquote:** Dies entspricht **{response_rate} %** der Gesamtsch√ºlerschaft.\n",
    "* **Klassenstufen:** {min_class_level} bis {max_class_level}.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Demografische Verteilung\n",
    "\n",
    "![Verteilung der Stichprobe nach Klassenstufe und Geschlecht. n={n_total}](img/chart_demographics.png)\n",
    "\n",
    "Die Stichprobe setzt sich wie folgt zusammen:\n",
    "\n",
    "* **Weiblich:** {pct_female} %\n",
    "* **M√§nnlich:** {pct_male} %\n",
    "* **Divers:** {pct_diverse} %\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Das soziale Klima (Schutzfaktoren)\n",
    "\n",
    "## 3.1 Wohlbefinden und Sicherheit\n",
    "\n",
    "![Zustimmungswerte zu Wohlbefinden und Sicherheit (Skala 1-5). n={n_respondents}](img/chart_wellbeing.png)\n",
    "\n",
    "* **Sicherheitsgef√ºhl:** **{pct_safety_high} %** der Befragten w√§hlten bei der Aussage \"Ich f√ºhle mich in meiner Klasse sicher\" die Werte 4 oder 5.\n",
    "* **Soziale Einbindung:** **{pct_friends_low} %** gaben an, keine engen FreundInnen in der Klasse zu haben (Werte 1 oder 2).\n",
    "\n",
    "## 3.2 Beziehung zu Lehrkr√§ften\n",
    "\n",
    "Die Wahrnehmung der Lehrkr√§fte zeigt folgende Mittelwerte (Skala 1-5):\n",
    "\n",
    "* **Gerechtigkeit:** $\\bar{{x}} =$ {mean_teacher_justice}\n",
    "* **Vertrauen:** $\\bar{{x}} =$ {mean_teacher_trust}\n",
    "* **Ernstgenommen werden:** $\\bar{{x}} =$ {mean_teacher_serious}\n",
    "\n",
    "(Legende: $\\bar{{x}} = Durchschnittswert)\n",
    "\n",
    "## 3.3 Wahrnehmung der Lehrer-Intervention\n",
    "\n",
    "Nehmen Sch√ºlerInnen wahr, dass Lehrkr√§fte Probleme erkennen und l√∂sen?\n",
    "\n",
    "* **Erkennen**: {pct_teachers_notice} % stimmen zu, dass Lehrer Mobbing bemerken (Frage 36).\n",
    "* **Handeln**: {pct_teachers_act} % stimmen zu, dass Lehrer auch tats√§chlich eingreifen (Frage 37).\n",
    "{gap_analysis_text}\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Pr√§valenz von Gewalt und Mobbing\n",
    "\n",
    "Betrachtungszeitraum: Letzte 6 Monate.\n",
    "\n",
    "## 4.1 Vergleich der Gewaltformen\n",
    "\n",
    "![Anteil betroffener Sch√ºlerInnen nach Gewaltform (mindestens \"Selten\"). n={n_total}](img/chart_violence_prevalence.png)\n",
    "\n",
    "* **Verbale/Soziale Gewalt:** {pct_verbal_any} %\n",
    "* **K√∂rperliche Gewalt:** {pct_physical_any} %\n",
    "* **Cybermobbing:** {pct_cyber_any} %\n",
    "\n",
    "## 4.2 Chronifizierung (Dauer)\n",
    "\n",
    "Von den betroffenen Sch√ºlerInnen geben **{pct_chronic} %** an, dass die Vorf√§lle bereits l√§nger als 6 Monate andauern.\n",
    "\n",
    "## 4.3 Altersabh√§ngigkeit (Klassenstufen)\n",
    "\n",
    "Die Analyse der Gewaltformen √ºber die verschiedenen Jahrgangsstufen zeigt folgende Entwicklungstendenzen:\n",
    "\n",
    "![Verlauf der Gewaltformen √ºber die Klassenstufen.](img/chart_violence_by_age.png)\n",
    "\n",
    "* **H√∂hepunkt:** Die h√∂chste Belastung zeigt sich in der Klassenstufe **{peak_violence_class}**.\n",
    "* **Trend:** Die Daten zeigen, dass k√∂rperliche Gewalt mit dem Alter eher {trend_physical_text}, verbale Gewalt eher {trend_verbal_text} und Cybermobbing eher {trend_cyber_text}.\n",
    "\n",
    "## 4.4 Geschlechtsspezifische Unterschiede\n",
    "\n",
    "Unterscheiden sich die Erfahrungen von M√§dchen, Jungen und diversen Sch√ºlerInnen?\n",
    "\n",
    "![Verteilung der Opfererfahrungen nach Geschlecht.](img/chart_gender_violence.png)\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Kontextfaktoren\n",
    "\n",
    "## 5.1 Orte und Zeiten\n",
    "\n",
    "![Heatmap der Tatorte und Tatzeiten (Gewichtet nach Aussagesch√§rfe). n={n_incidents}](img/chart_locations.png)\n",
    "\n",
    "Die Daten zeigen die h√∂chsten Nennungen f√ºr folgende Orte:\n",
    "\n",
    "1. **{top_location_1}**: {count_loc_1} Nennungen\n",
    "2. **{top_location_2}**: {count_loc_2} Nennungen\n",
    "\n",
    "Zeitliche Schwerpunkte:\n",
    "\n",
    "* **{top_time}**: {pct_top_time} % der F√§lle\n",
    "\n",
    "## 5.2 T√§terherkunft\n",
    "\n",
    "* **Klassenintern:** {pct_internal_perpetrators} % der Vorf√§lle gehen von Mitsch√ºlerInnen der eigenen Klasse aus.\n",
    "* **Gruppenagieren:** In {pct_group_bullying} % der F√§lle waren zwei oder mehr Personen beteiligt.\n",
    "\n",
    "## 5.3 Der \"T√§ter-Opfer-Zyklus\" (Bully-Victim-Ph√§nomen)\n",
    "\n",
    "Eine besondere Risikogruppe stellen Sch√ºlerInnen dar, die sowohl Opfer als auch T√§ter sind (sog. Bully-Victims).\n",
    "\n",
    "![√úberschneidung von T√§ter- und Opfergruppen mit Vorf√§llen h√§ufiger als einmal pro Monat.](img/chart_bully_victim_venn.png)\n",
    "\n",
    "* **Reine Opfer:** {pct_pure_victims} %\n",
    "* **Reine T√§ter:** {pct_pure_bullies} %\n",
    "* **T√§ter & Opfer:** **{pct_bully_victims} %** der Sch√ºlerInnen befinden sich in dieser Doppelrolle, die oft mit besonders hoher psychosozialer Belastung einhergeht.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Interventionskultur (Bystander)\n",
    "\n",
    "## 6.1 Die \"Zuschauer-L√ºcke\"\n",
    "\n",
    "* **Einstellung:** {pct_willingness} % geben an, sie w√ºrden \"Auf jeden Fall\" oder \"Wahrscheinlich\" helfen (Frage 30).\n",
    "* **Verhalten:** Mindestens einmal tats√§chlich eingegriffen (\"Ich habe versucht, dem Opfer direkt zu helfen\") haben in der Vergangenheit {pct_actual_help} % (Frage 32).\n",
    "\n",
    "## 6.2 An wen wenden sich Betroffene? (Dunkelfeld-Analyse)\n",
    "\n",
    "Interessant ist der Vergleich: An wen wenden sich Sch√ºlerInnen *theoretisch* (Frage 34) vs. an wen wenden sich *tats√§chliche Opfer*?\n",
    "\n",
    "![Kontaktpersonen: Gesamtheit vs. Tats√§chliche Opfer.](img/chart_reporting_behavior.png)\n",
    "\n",
    "* **Vertrauenslehrer:** Von den tats√§chlichen Opfern w√ºrden sich nur **{pct_victims_trust_teacher} %** an Vertrauenslehrer wenden.\n",
    "* **Isolation:** **{pct_victims_no_one} %** der betroffenen Sch√ºlerInnen geben an, niemanden zu haben, an den sie sich wenden w√ºrden.\n",
    "\n",
    "## 6.3 Strategien der Gegenwehr\n",
    "\n",
    "Wie reagieren Opfer auf √úbergriffe (Frage 26)?\n",
    "\n",
    "* **Konstruktiv**: {pct_defense_constructive} % (Hilfe holen, Weggehen).\n",
    "* **Destruktiv**: {pct_defense_aggressive} % (Zur√ºckschlagen, Beleidigen).\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Analyse der Schutzfaktoren\n",
    "\n",
    "Was sch√ºtzt Sch√ºlerInnen am effektivsten? Diese Analyse korreliert das Vorhandensein von unterst√ºtzenden Personen mit der allgemeinen Schulzufriedenheit (Wellbeing).\n",
    "\n",
    "![Korrelation von Freunden und Lehrkr√§ften und der Schulzufriedenheit.](img/chart_protective_factors.png)\n",
    "\n",
    "* **Befund:** Die Daten deuten darauf hin, dass **{strongest_protective_factor}** den st√§rksten positiven Zusammenhang mit dem Wohlbefinden aufweist.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Clusteranalyse (Risikogruppen & Personas)\n",
    "\n",
    "## 8.1 Methodik: KI-gest√ºtzte Mustererkennung\n",
    "\n",
    "Anstatt starrer Grenzwerte wurde in diesem Jahr ein **un√ºberwachter Lernalgorithmus (K-Means Clustering)** eingesetzt. Dieser analysiert s√§mtliche Antworten (Gewalt, soziales Umfeld, Lehrer-Beziehung) gleichzeitig, um verborgene Muster und Sch√ºlergruppen (\"Personas\") zu identifizieren.\n",
    "\n",
    "**Vorteil:** So werden auch Sch√ºlerInnen erkannt, die durch klassische Raster fallen (z.B. \"stille Opfer\" oder \"sozial integrierte Kritiker\").\n",
    "\n",
    "![Risiko-Matrix: Die identifizierten Cluster im Vergleich.](img/chart_risk_clusters.png)\n",
    "\n",
    "![PCA-Visualisierung der Entfernung zwischen den Clustern (Komponentenanalyse).](img/chart_pca_clusters.png)\n",
    "\n",
    "**Ergebnis der Analyse**:\n",
    "Der Algorithmus hat die Sch√ºlerschaft in verschiedene Cluster unterteilt. Eine davon wurde als **Hochrisiko-Gruppe ({n_risk_cluster} Sch√ºlerInnen, {pct_risk_cluster} %)** identifiziert.\n",
    "\n",
    "## 8.2 Profil der Gruppen\n",
    "Was unterscheidet die Risikogruppe von den anderen Clustern?\n",
    "\n",
    "![Detailliertes Profil der identifizierten Sch√ºlergruppen.](img/chart_risk_profile.png)\n",
    "\n",
    "![Spinnen-Diagramm: Visueller Vergleich der Auspr√§gungen.](img/chart_risk_radar.png)\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Motive & Hintergr√ºnde: Fremd- vs. Selbstbild\n",
    "\n",
    "Dieser Abschnitt vergleicht, *warum* Sch√ºlerInnen glauben, dass gemobbt wird (Frage 35), mit den Gr√ºnden, die T√§terInnen *selbst* angeben (Frage 41).\n",
    "\n",
    "![Vergleich der Motive: Wahrnehmung (Frage 35) vs. T√§ter-Aussage (Frage 41)](img/chart_motives_compare.png)\n",
    "\n",
    "## 9.1 Vermutete Motive (Zuschauer/Opfer)\n",
    "Die h√§ufigsten vermuteten Gr√ºnde f√ºr Mobbing sind:\n",
    "\n",
    "1. **{top_motive_perceived_1}** ({pct_motive_perceived_1} %)\n",
    "2. **{top_motive_perceived_2}** ({pct_motive_perceived_2} %)\n",
    "\n",
    "## 9.2 Berichtete Motive (Selbstauskunft T√§ter)\n",
    "Sch√ºlerInnen, die angaben, andere ge√§rgert zu haben ({pct_perpetrators} %), nennen folgende Gr√ºnde:\n",
    "\n",
    "1. **{top_motive_actual_1}** ({pct_motive_actual_1} %)\n",
    "2. **{top_motive_actual_2}** ({pct_motive_actual_2} %)\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Historische Entwicklung\n",
    "\n",
    "Wie haben sich die Zahlen im Vergleich zu den Vorjahren entwickelt?\n",
    "\n",
    "![Verlauf der Gewaltformen √ºber die Jahre](img/chart_trend_violence.png)\n",
    "\n",
    "* **K√∂rperliche Gewalt:** {trend_text_phys}\n",
    "* **Verbale Gewalt:** {trend_text_verb}\n",
    "* **Cybermobbing:** {trend_text_cyber}\n",
    "\n",
    "![Entwicklung des Sicherheitsgef√ºhls](img/chart_trend_safety.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Anhang A: Qualitative Auswertung & Freitexte\n",
    "\n",
    "Im Folgenden sind alle eingegangenen Freitext-Antworten kategorisiert aufgelistet.\n",
    "\n",
    "*Hinweis:* Bis auf eine manuelle Entfernung von Namen (Anonymisierung) wurden keine √Ñnderungen vorgenommen. \n",
    "\n",
    "\n",
    "## A.1 Spezifizierung der Gewaltformen (\"Anderes\")\n",
    "\n",
    "* **K√∂rperlich (Frage 16):**\n",
    "\n",
    "    * `{list_free_text_q16}`\n",
    "\n",
    "* **Verbal/Sozial (Frage 19):**\n",
    "\n",
    "    * `{list_free_text_q19}`\n",
    "\n",
    "* **Cybermobbing (Frage 22):**\n",
    "\n",
    "    * `{list_free_text_q22}`\n",
    "\n",
    "## A.2 Reaktionen und Abwehr\n",
    "\n",
    "* **Art der Gegenwehr (Frage 26 - Sonstiges):**\n",
    "\n",
    "    * `{list_free_text_q26}`\n",
    "\n",
    "* **Gedanken beim Beobachten (Frage 31 - Anderes):**\n",
    "\n",
    "    * `{list_free_text_q31}`\n",
    "\n",
    "* **Reaktion beim Beobachten (Frage 32 - Anderes):**\n",
    "\n",
    "    * `{list_free_text_q32}`\n",
    "\n",
    "## A.3 Orte und Unterst√ºtzung\n",
    "\n",
    "* **Andere Orte (Frage 28):**\n",
    "\n",
    "    * `{list_free_text_q28}`\n",
    "\n",
    "* **Andere Ansprechpersonen (Frage 34):**\n",
    "\n",
    "    * `{list_free_text_q34}`\n",
    "\n",
    "## A.4 Motive (Sonstiges)\n",
    "\n",
    "* **Vermutete Motive (Frage 35):**\n",
    "\n",
    "    * `{list_free_text_q35}`\n",
    "\n",
    "* **Selbstberichtete Motive (Frage 41):**\n",
    "\n",
    "    * `{list_free_text_q41}`\n",
    "\n",
    "## A.5 W√ºnsche und Feedback (Frage 42)#\n",
    "*\"Was w√ºnschst du dir? Was w√ºrde dir guttun, um dich wohlzuf√ºhlen?\"*\n",
    "\n",
    "*Hinweis:* Bis auf eine manuelle Entfernung von Namen (Anonymisierung) wurden keine √Ñnderungen vorgenommen. \n",
    "\n",
    "{open_text}\n",
    "\n",
    "## A.6 Wortwolke des Feedbacks\n",
    "![Wortwolke der Freitext-Antworten.](img/wordcloud_feedback.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Anhang B: Methodische Hinweise und statistische Verfahren\n",
    "\n",
    "Die vorliegende Auswertung basiert auf einer vollautomatisierten Datenverarbeitungspipeline (Python/Pandas), um Objektivit√§t und Reproduzierbarkeit zu gew√§hrleisten. Die methodische Vorgehensweise gliedert sich in folgende Schritte:\n",
    "\n",
    "## B.1 Datenbereinigung und Preprocessing\n",
    "Vor der statistischen Analyse durchlief der Rohdatensatz einen mehrstufigen Bereinigungsprozess:\n",
    "\n",
    "* **Validierung:** Antworten wurden auf Plausibilit√§t gepr√ºft und Zeitstempel zur Abgrenzung des Erhebungszeitraums gefiltert.\n",
    "* **Text-Sanitisierung:** Freitext-Antworten wurden automatisiert von potenziell sch√§dlichen Zeichencodes (LaTeX-Syntax) bereinigt und anonymisiert.\n",
    "* **Imputation fehlender Werte:** Um den Informationsverlust bei multivariaten Analysen (z. B. Clustering) zu minimieren, kam ein Imputationsverfahren (`SimpleImputer`) zum Einsatz. Fehlende Werte in Likert-Skalen wurden durch den **Median** der jeweiligen Variable ersetzt, da dieser robust gegen√ºber Ausrei√üern ist und die ordinale Struktur der Daten wahrt.\n",
    "\n",
    "## B.2 Gewichtete Analyse (\"Aussagesch√§rfe\")\n",
    "Eine besondere Herausforderung bei der Analyse von Tatorten und Tatzeiten (Abbildung 6) ist das Antwortverhalten: Sch√ºlerInnen, die *alle* Optionen ankreuzen, verzerren in herk√∂mmlichen Auswertungen das Bild gegen√ºber jenen, die sehr spezifische Angaben machen.\n",
    "\n",
    "Um dies zu korrigieren, wurde das Verfahren des **Fractional Counting** angewandt:\n",
    "\n",
    "* Jeder gemeldete Vorfall erh√§lt das Gesamtgewicht von $1.0$.\n",
    "* Dieses Gewicht wird gleichm√§√üig auf die angekreuzten Kombinationen verteilt.\n",
    "* *Beispiel:* Kreuzt ein Sch√ºler 2 Orte und 2 Zeiten an, entstehen 4 Kombinationen. Jede Kombination z√§hlt in der Heatmap nicht als $1$, sondern als $0.25$ ($1 / (2 \\times 2)$).\n",
    "* **Effekt:** Die Heatmap zeigt somit keine blo√üen Nennungen, sondern die *konzentrierte Wahrscheinlichkeitsdichte* der Vorf√§lle.\n",
    "\n",
    "## B.3 Multidimensionale Mustererkennung (Clusteranalyse)\n",
    "Anstelle starrer Grenzwerte wurde ein un√ºberwachtes maschinelles Lernverfahren eingesetzt, um komplexe Sch√ºler-Profile (\"Personas\") zu identifizieren.\n",
    "\n",
    "* **Algorithmus:** Verwendet wurde der **K-Means-Algorithmus** ($k=3$), der Datens√§tze in Gruppen unterteilt, sodass die Varianz innerhalb der Cluster minimiert wird.\n",
    "* **Feature-Engineering:** In die Analyse flossen sowohl Belastungsfaktoren (Gewalth√§ufigkeiten, numerisch 0‚Äì5) als auch Ressourcen (sozialer R√ºckhalt, Lehrerbeziehung, imputiert) ein.\n",
    "* **Standardisierung:** Da die verwendeten Skalen unterschiedliche Wertebereiche aufweisen, wurde vor der Clusterung eine **Z-Transformation (Standard Scaler)** durchgef√ºhrt.\n",
    "* **Automatisches Labeling:** Die Benennung der Cluster (\"Risikogruppe\", \"System-Kritiker\", \"Integrierte\") erfolgt dynamisch anhand definierter Schwellenwerte (z. B. *Vertrauens-Score < 3.2* bei gleichzeitiger *Gewaltfreiheit* f√ºr Kritiker).\n",
    "\n",
    "## B.4 KI-gest√ºtzte Zusammenfassung (Human-in-the-Loop)\n",
    "Die textlichen Zusammenfassungen (\"Abstract\" und \"Executive Summary\") wurden initial durch ein Large Language Model (LLM) auf Basis der statistischen Rohdaten generiert.\n",
    "\n",
    "* **Prozess:** Der generierte Text wird nicht ungepr√ºft √ºbernommen. Das System erzwingt einen **Human-in-the-Loop**-Schritt: Der Autor des Berichts bekommt den Vorschlag angezeigt und muss diesen aktiv best√§tigen, korrigieren oder verwerfen, bevor er in das PDF kompiliert wird.\n",
    "* **Ziel:** Dies kombiniert die analytische Effizienz der KI mit der p√§dagogischen Verantwortung und Kontextkompetenz des menschlichen Autors.\n",
    "\n",
    "## B.5 Langzeit-Monitoring und Datenschutz\n",
    "Um Entwicklungen √ºber mehrere Schuljahre hinweg vergleichbar zu machen, werden die aggregierten Kennzahlen (nicht die Rohdaten) in einem persistierten JSON-Format bin√§r an das Ende der PDF-Datei angeh√§ngt. Dies erm√∂glicht eine historische Trendanalyse direkt aus den Berichten der Vorjahre, ohne dass datenschutzrechtlich sensible Rohdaten (CSV) dauerhaft gespeichert werden m√ºssen.\n",
    "\n",
    "---\n",
    "\n",
    "{feedback_section_placeholder}\n",
    "\n",
    "{ai_executive_summary}\n",
    "\n",
    "---\n",
    "\n",
    "# Schlusswort und Ausblick\n",
    "\n",
    "Dieser Bericht ist mehr als eine Ansammlung von Zahlen und Diagrammen. Er ist ein Spiegelbild unserer aktuellen Schulgemeinschaft ‚Äì mit all ihren St√§rken, aber auch ihren Schattenseiten.\n",
    "\n",
    "Besonders danken m√∂chten wir den **{n_total} Sch√ºlerinnen und Sch√ºlern**, die den Mut hatten, ehrlich zu antworten. Eure Offenheit macht sichtbar, was im Alltag oft verborgen bleibt. Die Daten zeigen uns deutlich: Wir haben eine solide Basis an Vertrauen und Sicherheit, aber wir d√ºrfen die Augen vor den real existierenden Konflikten und N√∂ten einzelner Sch√ºlergruppen nicht verschlie√üen.\n",
    "\n",
    "Zahlen allein ver√§ndern noch kein Schulklima. Sie sind aber der notwendige Startpunkt f√ºr das Gespr√§ch. Es liegt nun an uns ‚Äì dem Kollegium, der Elternschaft und der SV ‚Äì, diese Erkenntnisse in p√§dagogisches Handeln zu √ºbersetzen, damit sich *jedes* Kind an unserer Schule nicht nur unterrichtet, sondern auch sicher und gesehen f√ºhlt.\n",
    "\n",
    "Lassen Sie uns diese Auswertung als Auftrag verstehen, hinschauen statt wegsehen und gemeinsam an einer Kultur der Achtsamkeit weiterarbeiten.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt(val, decimals=1):\n",
    "    \"\"\"\n",
    "    Formatiert Zahlen deutsch (57.6 -> 57,6).\n",
    "    Gibt Strings (z.B. \"N/A\") unver√§ndert zur√ºck, statt abzust√ºrzen.\n",
    "    \"\"\"\n",
    "    # 1. Schutzmechanismus: Ist es schon ein Text? (z.B. \"N/A\")\n",
    "    if isinstance(val, str):\n",
    "        return val.replace('.', ',') # Falls im Text Punkte sind, sicherheitshalber tauschen\n",
    "    \n",
    "    # 2. Schutzmechanismus: Ist es None?\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "        \n",
    "    # 3. Eigentliche Formatierung f√ºr Zahlen\n",
    "    try:\n",
    "        format_str = f\"{{:.{decimals}f}}\"\n",
    "        return format_str.format(val).replace('.', ',')\n",
    "    except (ValueError, TypeError):\n",
    "        # Fallback, falls irgendwas anderes Komisches reinkommt\n",
    "        return str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Replace Placeholders in Template (1)\n",
    "template = template.replace(\"{author}\", author_name)\n",
    "template = template.replace(\"{date_today}\", date_today)\n",
    "\n",
    "template = template.replace(\"{school_year}\", school_year)\n",
    "\n",
    "# Determine data collection period from timestamp range in df\n",
    "min_date = pd.to_datetime(df['Submitted at']).min().strftime('%d.%m.%Y')\n",
    "max_date = pd.to_datetime(df['Submitted at']).max().strftime('%d.%m.%Y')\n",
    "data_collection_period = f\"{min_date} bis {max_date}\"\n",
    "template = template.replace(\"{data_collection_period}\", data_collection_period)\n",
    "\n",
    "# Total respondents\n",
    "num_total = len(df)\n",
    "num_overall = num_total + num_suspicious\n",
    "template = template.replace(\"{n_overall}\", str(num_overall))\n",
    "template = template.replace(\"{n_suspicious}\", str(num_suspicious))\n",
    "template = template.replace(\"{n_total}\", str(num_total))\n",
    "\n",
    "# Response rate\n",
    "if student_count == 0:\n",
    "    response_rate = \"N/A\"\n",
    "else:\n",
    "    response_rate = round((num_total / student_count) * 100, 1)\n",
    "template = template.replace(\"{response_rate}\", fmt(response_rate))\n",
    "\n",
    "# Class levels min/max (format: \"10. Klasse\")\n",
    "class_levels = df[\"class_level\"].dropna().unique()\n",
    "class_levels_sorted = sorted(class_levels, key=lambda x: int(x.split('.')[0]))\n",
    "min_class_level = class_levels_sorted[0]\n",
    "max_class_level = class_levels_sorted[-1]\n",
    "template = template.replace(\"{min_class_level}\", min_class_level)\n",
    "template = template.replace(\"{max_class_level}\", max_class_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb712516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Calculate Gender Distribution and Replace in Template (2)\n",
    "\n",
    "gender_counts = df['gender'].value_counts(normalize=True) * 100\n",
    "pct_female = round(gender_counts.get('weiblich', 0), 1)\n",
    "pct_male = round(gender_counts.get('m√§nnlich', 0), 1)\n",
    "pct_diverse = round(gender_counts.get('divers', 0), 1)\n",
    "template = template.replace(\"{pct_female}\", fmt(pct_female))\n",
    "template = template.replace(\"{pct_male}\", fmt(pct_male))\n",
    "template = template.replace(\"{pct_diverse}\", fmt(pct_diverse))  \n",
    "\n",
    "# Stacked bar chart per class level and gender\n",
    "demographics = df.groupby(['class_level', 'gender']).size().unstack(fill_value=0)\n",
    "demographics = demographics.reindex(class_levels_sorted)  # Ensure correct order\n",
    "\n",
    "# Calculate students who didn't answer the gender question per grade\n",
    "total_per_class = df['class_level'].value_counts()\n",
    "not_answered = total_per_class - demographics.sum(axis=1)\n",
    "demographics['N/A'] = not_answered\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "ax = demographics.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.xlabel('Klassenstufe')\n",
    "plt.ylabel('Anzahl der Sch√ºlerInnen')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(np.arange(0, demographics.values.max() + 5, 5))\n",
    "plt.legend(title='Geschlechtsangabe')\n",
    "\n",
    "# Add total number of submissions per class on top of each bar\n",
    "for i, total in enumerate(total_per_class.reindex(class_levels_sorted)):\n",
    "    ax.annotate(str(total), xy=(i, total), xytext=(0, 3), \n",
    "                textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_demographics.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Well-being and Safety: Calculations and Diverging Bar Charts (3.1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# --- Existing calculation for template variables ---\n",
    "n_respondents = len(df[['safety_in_class', 'friends_in_class']].dropna())\n",
    "template = template.replace(\"{n_respondents}\", str(n_respondents))\n",
    "\n",
    "safety_counts = df['safety_in_class'].value_counts(normalize=True) * 100\n",
    "pct_safety_high = round(safety_counts[safety_counts.index.isin([4, 5])].sum(), 1)\n",
    "template = template.replace(\"{pct_safety_high}\", fmt(pct_safety_high))\n",
    "\n",
    "friends_counts = df['friends_in_class'].value_counts(normalize=True) * 100\n",
    "pct_friends_low = round(friends_counts[friends_counts.index.isin([1, 2])].sum(), 1)\n",
    "template = template.replace(\"{pct_friends_low}\", fmt(pct_friends_low))\n",
    "\n",
    "\n",
    "# Questions for well-being and safety\n",
    "wellbeing_questions = [\n",
    "    'friends_in_class',\n",
    "    'respect_in_class',\n",
    "    'liked_by_others',\n",
    "    'safety_in_class',\n",
    "    'like_school'\n",
    "]\n",
    "\n",
    "# Labels for the questions\n",
    "question_labels = [q['long_question'] for q in survey if q['short_id'] in wellbeing_questions]\n",
    "\n",
    "# Wrap labels for better readability\n",
    "wrapped_labels = [textwrap.fill(label, width=40) for label in question_labels]\n",
    "\n",
    "# Calculate distribution (1-2: negative, 3: neutral, 4-5: positive)\n",
    "response_categories = ['Negativ (1-2)', 'Neutral (3)', 'Positiv (4-5)']\n",
    "category_counts = [] # Stores percentages for plotting\n",
    "category_ns = []     # Stores absolute counts for labels\n",
    "\n",
    "for question in wellbeing_questions:\n",
    "    # Calculate Percentages\n",
    "    counts = df[question].value_counts(normalize=True) * 100\n",
    "    negative = counts[counts.index.isin([1, 2])].sum()\n",
    "    neutral = counts[counts.index.isin([3])].sum()\n",
    "    positive = counts[counts.index.isin([4, 5])].sum()\n",
    "    category_counts.append([negative, neutral, positive])\n",
    "\n",
    "    # Calculate Absolute Counts (n)\n",
    "    abs_counts = df[question].value_counts()\n",
    "    negative_n = abs_counts[abs_counts.index.isin([1, 2])].sum()\n",
    "    neutral_n = abs_counts[abs_counts.index.isin([3])].sum()\n",
    "    positive_n = abs_counts[abs_counts.index.isin([4, 5])].sum()\n",
    "    category_ns.append([negative_n, neutral_n, positive_n])\n",
    "\n",
    "# DataFrame for visualization (percentages)\n",
    "category_df = pd.DataFrame(category_counts, columns=response_categories, index=wrapped_labels)\n",
    "# DataFrame for annotations (counts)\n",
    "counts_df = pd.DataFrame(category_ns, columns=response_categories, index=wrapped_labels)\n",
    "\n",
    "# Diverging bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Stacked Bar Chart\n",
    "category_df.plot(kind='barh', stacked=True, color=['#f44336', '#ffeb3b', '#4caf50'], ax=ax, edgecolor='black')\n",
    "\n",
    "# Add \"n\" labels to each bar segment\n",
    "for c, col in zip(ax.containers, counts_df.columns):\n",
    "    # Get the counts for the current category (column)\n",
    "    labels = [f\"n={int(v)}\" if v > 0 else \"\" for v in counts_df[col]]\n",
    "    ax.bar_label(c, labels=labels, label_type='center', fontsize=9)\n",
    "\n",
    "# Axis titles and labels\n",
    "plt.xlabel('Anteil der Antworten (%)')\n",
    "plt.ylabel('Fragen')\n",
    "plt.xlim(0, 100)\n",
    "plt.legend(title='Antwortkategorien', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('img/chart_wellbeing.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Relationship with Teachers: Calculations and Replace in Template (3.2)\n",
    "teacher_questions = [\n",
    "    'teacher_fairness',\n",
    "    'teacher_trust',\n",
    "    'teacher_care'\n",
    "]\n",
    "\n",
    "mean_teacher_justice = round(df['teacher_fairness'].mean(), 2)\n",
    "mean_teacher_trust = round(df['teacher_trust'].mean(), 2)\n",
    "mean_teacher_serious = round(df['teacher_care'].mean(), 2)\n",
    "\n",
    "template = template.replace(\"{mean_teacher_justice}\", fmt(mean_teacher_justice, 2))\n",
    "template = template.replace(\"{mean_teacher_trust}\", fmt(mean_teacher_trust, 2))\n",
    "template = template.replace(\"{mean_teacher_serious}\", fmt(mean_teacher_serious, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Teacher Intervention Perception: Calculations and Replace in Template (3.3)\n",
    "\n",
    "# 1. Daten berechnen\n",
    "teachers_notice_counts = df['teachers_notice_bullying'].value_counts(normalize=True) * 100\n",
    "pct_teachers_notice = round(teachers_notice_counts[teachers_notice_counts.index.isin([4, 5])].sum(), 1)\n",
    "template = template.replace(\"{pct_teachers_notice}\", str(pct_teachers_notice))\n",
    "\n",
    "teachers_intervene_counts = df['teachers_intervene_bullying'].value_counts(normalize=True) * 100\n",
    "pct_teachers_act = round(teachers_intervene_counts[teachers_intervene_counts.index.isin([4, 5])].sum(), 1)\n",
    "template = template.replace(\"{pct_teachers_act}\", str(pct_teachers_act))\n",
    "\n",
    "# 2. Dynamische Text-Generierung\n",
    "diff = pct_teachers_notice - pct_teachers_act\n",
    "\n",
    "if pct_teachers_act > pct_teachers_notice:\n",
    "    # Fall A: Lehrer w√ºrden helfen, sehen es aber nicht\n",
    "    # Interpretation: Das Problem ist die Wahrnehmung (\"Dunkelfeld\")\n",
    "    text = (\n",
    "        f\"* **Analyse**: Die Daten weisen auf ein **Wahrnehmungsdefizit** hin. \"\n",
    "        f\"W√§hrend {fmt(pct_teachers_act)} % der Sch√ºlerInnen Vertrauen in das Eingreifen der Lehrkr√§fte haben, \"\n",
    "        f\"geben nur {fmt(pct_teachers_notice)} % an, dass Vorf√§lle √ºberhaupt bemerkt werden. \"\n",
    "        f\"Lehrkr√§fte werden also als hilfsbereit, aber oft unwissend wahrgenommen.\"\n",
    "    )\n",
    "\n",
    "elif diff > 5.0:\n",
    "    # Fall B: Lehrer sehen es, tun aber nichts (Klassische \"L√ºcke\")\n",
    "    # Interpretation: Das Problem ist die Handlung (\"Wegschauen\")\n",
    "    text = (\n",
    "        f\"* **Handlungsl√ºcke**: Hier zeigt sich eine signifikante Diskrepanz. \"\n",
    "        f\"Obwohl {fmt(pct_teachers_notice)} % angeben, dass Lehrer Mobbing bemerken, \"\n",
    "        f\"best√§tigen deutlich weniger ({fmt(pct_teachers_act)}) %, dass auch eingegriffen wird. \"\n",
    "        f\"Dies deutet darauf hin, dass beobachtete Vorf√§lle oft ohne Konsequenzen bleiben.\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Fall C: Werte sind ungef√§hr gleich\n",
    "    text = (\n",
    "        f\"* **Balance**: Die Wahrnehmung von Vorf√§llen und die Bereitschaft zum Eingreifen \"\n",
    "        f\"liegen auf einem √§hnlichen Niveau (Differenz: {fmt(round(abs(diff), 1), 1)} Prozentpunkte).\"\n",
    "    )\n",
    "\n",
    "# 3. Platzhalter im Template ersetzen\n",
    "template = template.replace(\"{gap_analysis_text}\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb04070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Prevalence of Violence Forms: Calculations and Diagram (Stacked Bar Chart) (4.1)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the frequency categories and their logical order\n",
    "frequency_categories = ['Selten', 'Monatlich', 'W√∂chentlich', 'Mehrmals pro Woche', 'T√§glich']\n",
    "colors = ['#d4e157', '#ffeb3b', '#ff9800', '#f44336', '#b71c1c'] \n",
    "\n",
    "# Function to compute frequency distribution for a given column\n",
    "def compute_frequency_distribution(df, freq_col):\n",
    "    freq_distribution = df[freq_col].value_counts(normalize=True) * 100\n",
    "    freq_distribution = freq_distribution.reindex(frequency_categories, fill_value=0)\n",
    "    return freq_distribution\n",
    "\n",
    "# Compute frequency distributions for each violence type\n",
    "verbal_distribution = compute_frequency_distribution(df, 'verbal_violence_freq')\n",
    "physical_distribution = compute_frequency_distribution(df, 'physical_violence_freq')\n",
    "cyber_distribution = compute_frequency_distribution(df, 'cyberbullying_freq')\n",
    "\n",
    "def compute_violence_prevalence(df, freq_col):\n",
    "    freq_counts = df[freq_col].value_counts(normalize=True) * 100\n",
    "    pct_any = round(freq_counts[freq_counts.index.isin(['Selten', 'Monatlich', 'W√∂chentlich', 'Mehrmals pro Woche', 'T√§glich'])].sum(), 1)\n",
    "    return pct_any\n",
    "\n",
    "pct_verbal_any = compute_violence_prevalence(df, 'verbal_violence_freq')\n",
    "pct_physical_any = compute_violence_prevalence(df, 'physical_violence_freq')\n",
    "pct_cyber_any = compute_violence_prevalence(df, 'cyberbullying_freq')\n",
    "\n",
    "template = template.replace(\"{pct_verbal_any}\", fmt(pct_verbal_any))\n",
    "template = template.replace(\"{pct_physical_any}\", fmt(pct_physical_any))\n",
    "template = template.replace(\"{pct_cyber_any}\", fmt(pct_cyber_any))\n",
    "\n",
    "# Combine the distributions into a DataFrame\n",
    "violence_data = pd.DataFrame({\n",
    "    'Verbale/Soziale Gewalt': verbal_distribution,\n",
    "    'K√∂rperliche Gewalt': physical_distribution,\n",
    "    'Cybermobbing': cyber_distribution\n",
    "}).T\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PLOTTING SECTION (Updated Layout)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Increase figure size slightly to accommodate outside labels\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "violence_data.plot(kind='bar', stacked=True, ax=ax, color=colors, edgecolor='black', width=0.6, linewidth=0.5)\n",
    "\n",
    "# Styling\n",
    "plt.ylabel('Anteil betroffener Sch√ºlerInnen (%)')\n",
    "plt.xlabel('Gewaltform')\n",
    "\n",
    "# --- DYNAMIC Y-AXIS SCALING ---\n",
    "# Calculate the max total height across all bars\n",
    "max_height = violence_data.sum(axis=1).max()\n",
    "# Set limit to max height + 15% buffer for the \"Total\" labels\n",
    "ax.set_ylim(0, max_height * 1.15) \n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Move legend outside to the right\n",
    "plt.legend(title='H√§ufigkeit', labels=frequency_categories, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Clean up axes\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(color='gray', linestyle='dashed', alpha=0.3)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# --- SMART LABELING LOGIC ---\n",
    "THRESHOLD = 4.5  # If a segment is smaller than 4.5%, move label outside\n",
    "\n",
    "# Iterate over each \"Stack\" (each bar on the X axis)\n",
    "n_bars = len(violence_data)\n",
    "bar_width = 0.6\n",
    "\n",
    "for bar_idx in range(n_bars):\n",
    "    \n",
    "    # Collect all segments for this specific bar\n",
    "    segments = []\n",
    "    current_y = 0\n",
    "    row_data = violence_data.iloc[bar_idx]\n",
    "    small_labels = [] \n",
    "    \n",
    "    for cat_idx, value in enumerate(row_data):\n",
    "        if value > 0:\n",
    "            center_y = current_y + value / 2\n",
    "            \n",
    "            # CASE 1: BIG SEGMENT (Inside)\n",
    "            if value >= THRESHOLD:\n",
    "                t_color = 'black' if cat_idx < 3 else 'white'\n",
    "                ax.text(bar_idx, center_y, f\"{fmt(value)}%\", \n",
    "                        ha='center', va='center', color=t_color, fontsize=9, weight='bold')\n",
    "            \n",
    "            # CASE 2: SMALL SEGMENT (Outside)\n",
    "            else:\n",
    "                small_labels.append({\n",
    "                    'value': value,\n",
    "                    'y_real': center_y,\n",
    "                })\n",
    "        \n",
    "        current_y += value\n",
    "\n",
    "    # --- PROCESS SMALL LABELS (The \"Spread\" Logic) ---\n",
    "    if small_labels:\n",
    "        # Sort by height so we process bottom-up\n",
    "        small_labels.sort(key=lambda x: x['y_real'])\n",
    "        \n",
    "        # Determine spacing based on the dynamic scale\n",
    "        # (Larger scale = smaller spread needed in absolute units)\n",
    "        last_text_y = -100 \n",
    "        min_distance = max_height * 0.05 # Dynamic spacing (5% of total height)\n",
    "        \n",
    "        for lbl in small_labels:\n",
    "            text_y = lbl['y_real']\n",
    "            \n",
    "            # Push label up if it overlaps with previous\n",
    "            if text_y < last_text_y + min_distance:\n",
    "                text_y = last_text_y + min_distance\n",
    "            \n",
    "            last_text_y = text_y\n",
    "            label_str = f\"{lbl['value']:.1f}%\"\n",
    "            \n",
    "            # Calculate right edge of bar\n",
    "            bar_right_edge = bar_idx + (bar_width / 2)\n",
    "            \n",
    "            ax.annotate(\n",
    "                label_str,\n",
    "                xy=(bar_right_edge, lbl['y_real']),\n",
    "                xytext=(bar_right_edge + 0.2, text_y),\n",
    "                arrowprops=dict(arrowstyle=\"-\", color='black', linewidth=0.5, relpos=(0, 0.5)),\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                fontsize=9,\n",
    "                color='#333333'\n",
    "            )\n",
    "\n",
    "# Add Totals on top\n",
    "totals = violence_data.sum(axis=1)\n",
    "for i, total in enumerate(totals):\n",
    "    # Dynamic offset for total label\n",
    "    offset = max_height * 0.02 \n",
    "    ax.text(i, total + offset, f\"Total: {total:.1f}%\", ha='center', va='bottom', fontsize=10, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_violence_prevalence.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Calculate Chronification and Replace in Template (4.2)\n",
    "\n",
    "chronic_conditions = ['physical_violence_duration', 'verbal_violence_duration', 'cyberbullying_freq']\n",
    "chronic_counts = 0\n",
    "total_affected = 0\n",
    "for col in chronic_conditions:\n",
    "    affected = df[df[col].isin(['Mehr als 2 Jahre', '1-2 Jahre', '6-12 Monate'])]\n",
    "    chronic_counts += len(affected)\n",
    "    total_affected += len(df[df[col].notna()])\n",
    "\n",
    "pct_chronic = round((chronic_counts / total_affected) * 100, 1) if total_affected > 0 else 0\n",
    "template = template.replace(\"{pct_chronic}\", fmt(pct_chronic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Altersabh√§ngigkeit & Intensit√§t der Gewalt: Berechnung und Diagramm (4.3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 1. Datenvorbereitung\n",
    "freq_map = {\n",
    "    'Nie': 0, 'Selten': 1, 'Monatlich': 2,\n",
    "    'W√∂chentlich': 3, 'Ungef√§hr einmal pro Woche': 3,\n",
    "    'Mehrmals pro Woche': 4, 'T√§glich': 5\n",
    "}\n",
    "\n",
    "def to_score(col):\n",
    "    return df[col].map(freq_map).fillna(0)\n",
    "\n",
    "df['score_phys'] = to_score('physical_violence_freq')\n",
    "df['score_verb'] = to_score('verbal_violence_freq')\n",
    "df['score_cyber'] = to_score('cyberbullying_freq')\n",
    "\n",
    "# 2. Aggregation (Rot/H√§ufig vs. Gelb/Selten)\n",
    "def get_stacked_data(col):\n",
    "    freq = df.groupby('class_level')[col].apply(lambda x: (x >= 2).mean() * 100)\n",
    "    rare = df.groupby('class_level')[col].apply(lambda x: (x == 1).mean() * 100)\n",
    "    return pd.DataFrame({'H√§ufig (mind. monatlich)': freq, 'Selten': rare}).reindex(class_levels_sorted)\n",
    "\n",
    "phys_stack = get_stacked_data('score_phys')\n",
    "verb_stack = get_stacked_data('score_verb')\n",
    "cyber_stack = get_stacked_data('score_cyber')\n",
    "\n",
    "# 3. Plotting (Kombiniertes Diagramm)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "colors = ['#d62728', '#fecb52'] \n",
    "class_counts = df['class_level'].value_counts().reindex(class_levels_sorted)\n",
    "labels_with_n = [f\"{cls}\\n(n={class_counts.get(cls, 0)})\" for cls in class_levels_sorted]\n",
    "\n",
    "def plot_stack(data, ax, title, show_legend=False):\n",
    "    data.plot(kind='bar', stacked=True, ax=ax, color=colors, edgecolor='black', width=0.8)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xticklabels(labels_with_n, rotation=45, ha='right')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('')\n",
    "    if show_legend:\n",
    "        ax.legend(title='Intensit√§t', loc='upper right', labels=['H√§ufig / Systematisch', 'Selten / Einzelf√§lle'])\n",
    "    else:\n",
    "        if ax.get_legend(): ax.get_legend().remove()\n",
    "\n",
    "plot_stack(phys_stack, axes[0], 'K√∂rperliche Gewalt')\n",
    "axes[0].set_ylabel('Anteil betroffener Sch√ºlerInnen (%)', fontsize=12)\n",
    "plot_stack(verb_stack, axes[1], 'Verbale/Soziale Gewalt', show_legend=True)\n",
    "plot_stack(cyber_stack, axes[2], 'Cybermobbing')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('img/chart_violence_by_age.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Berechnung der \"Problemklasse\" (Peak)\n",
    "avg_freq_risk = (phys_stack['H√§ufig (mind. monatlich)'] + \n",
    "                 verb_stack['H√§ufig (mind. monatlich)'] + \n",
    "                 cyber_stack['H√§ufig (mind. monatlich)']) / 3\n",
    "peak_violence_class = avg_freq_risk.idxmax() if not avg_freq_risk.dropna().empty else \"N/A\"\n",
    "template = template.replace(\"{peak_violence_class}\", str(peak_violence_class))\n",
    "\n",
    "# 5. Trend-Analyse (Grammatikalisch angepasst f√ºr den Satz)\n",
    "def determine_trend_verb(series):\n",
    "    y = series.values\n",
    "    if len(y) < 2: return \"unklar ist\"\n",
    "    x = np.arange(len(y))\n",
    "    mask = ~np.isnan(y)\n",
    "    if mask.sum() < 2: return \"unklar ist\"\n",
    "    slope, _, _, _, _ = linregress(x[mask], y[mask])\n",
    "    \n",
    "    # R√ºckgabe von Verben f√ºr den Flie√ütext\n",
    "    if slope > 2: return \"zunimmt\"      # Steigung > 2%\n",
    "    elif slope < -2: return \"abnimmt\"   # Steigung < -2%\n",
    "    else: return \"stabil bleibt\"\n",
    "\n",
    "# Berechnung der Trends\n",
    "trend_phys = determine_trend_verb(phys_stack['H√§ufig (mind. monatlich)'])\n",
    "trend_verb = determine_trend_verb(verb_stack['H√§ufig (mind. monatlich)'])\n",
    "trend_cyber = determine_trend_verb(cyber_stack['H√§ufig (mind. monatlich)'])\n",
    "\n",
    "# Ersetzen der Platzhalter im Template\n",
    "# Hinweis: Wir nutzen die neuen Platzhalter-Namen aus Ihrer Anfrage\n",
    "template = template.replace(\"{trend_physical_text}\", trend_phys)\n",
    "template = template.replace(\"{trend_verbal_text}\", trend_verb)\n",
    "template = template.replace(\"{trend_cyber_text}\", trend_cyber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79b23b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Gender-Specific Differences: Calculations and Diagram (4.4)\n",
    "\n",
    "# Translation for violence form\n",
    "violence_translation = {\n",
    "    'physical_violence_freq': 'K√∂rperliche Gewalt',\n",
    "    'verbal_violence_freq': 'Verbale/Soziale Gewalt',\n",
    "    'cyberbullying_freq': 'Cybermobbing'\n",
    "}\n",
    "\n",
    "# Add respondent counts to gender labels\n",
    "gender_counts = df['gender'].value_counts()\n",
    "gender_labels = { \n",
    "    'weiblich': f\"Weiblich (n={gender_counts.get('weiblich', 0)})\", \n",
    "    'm√§nnlich': f\"M√§nnlich (n={gender_counts.get('m√§nnlich', 0)})\", \n",
    "    'divers': f\"Divers (n={gender_counts.get('divers', 0)})\" \n",
    "}\n",
    "\n",
    "# Filter out groups with fewer than 5 responses\n",
    "excluded_groups = gender_counts[gender_counts < 5]\n",
    "excluded_count = excluded_groups.sum()\n",
    "gender_counts = gender_counts[gender_counts >= 5]  # Keep only groups with n >= 5\n",
    "\n",
    "# If all groups are excluded, skip the chart\n",
    "if gender_counts.empty:\n",
    "    print(f\"{excluded_count} Antworten wurden wegen zu kleiner Gruppen ausgeblendet.\")\n",
    "else:\n",
    "    gender_violence = df[df['gender'].isin(gender_counts.index)].groupby('gender').agg({\n",
    "        'physical_violence_freq': lambda x: compute_violence_prevalence(df.loc[x.index], 'physical_violence_freq'),\n",
    "        'verbal_violence_freq': lambda x: compute_violence_prevalence(df.loc[x.index], 'verbal_violence_freq'),\n",
    "        'cyberbullying_freq': lambda x: compute_violence_prevalence(df.loc[x.index], 'cyberbullying_freq')\n",
    "    }).reset_index()\n",
    "\n",
    "    # Map gender labels\n",
    "    gender_violence['gender_label'] = gender_violence['gender'].map(gender_labels)\n",
    "\n",
    "    # Melt the dataframe and translate violence form\n",
    "    gender_violence_melted = gender_violence.melt(\n",
    "        id_vars='gender_label', \n",
    "        value_vars=['physical_violence_freq', 'verbal_violence_freq', 'cyberbullying_freq'],\n",
    "        var_name='Gewaltform', \n",
    "        value_name='Anteil (%)'\n",
    "    )\n",
    "    gender_violence_melted['Gewaltform'] = gender_violence_melted['Gewaltform'].map(violence_translation)\n",
    "\n",
    "    # Plotting\n",
    "    ax = sns.barplot(\n",
    "        data=gender_violence_melted, \n",
    "        x='Gewaltform', \n",
    "        y='Anteil (%)', \n",
    "        hue='gender_label', \n",
    "        palette='pastel'\n",
    "    )\n",
    "\n",
    "    plt.ylabel('Anteil betroffener Sch√ºlerInnen (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlabel('Gewaltform')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Geschlecht')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add a note about excluded groups\n",
    "    if excluded_count > 0:\n",
    "        plt.figtext(0.5, -0.1, f\"{excluded_count} Antworten wurden wegen zu kleiner Gruppen ausgeblendet.\", \n",
    "                wrap=True, horizontalalignment='center', fontsize=10)\n",
    "\n",
    "plt.savefig('img/chart_gender_violence.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dded6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Locations and Times of Bullying: Calculations and Diagram (Heatmap) (5.1)\n",
    "\n",
    "location_options = {\n",
    "    \"classroom\": \"Klassenzimmer\",\n",
    "    \"schoolyard\": \"Schulhof\",\n",
    "    \"hallway\": \"Treppenhaus/Flur\",\n",
    "    \"restrooms\": \"Toiletten\",\n",
    "    \"way_to_school\": \"Schulweg\",\n",
    "    \"online\": \"Online\",\n",
    "    \"elsewhere\": \"Anderswo\"\n",
    "}\n",
    "\n",
    "time_options = {\n",
    "    \"during_class\": \"W√§hrend des Unterrichts\",\n",
    "    \"during_breaks\": \"In den Pausen\",\n",
    "    \"before_after_school\": \"Vor oder nach der Schule\"\n",
    "}\n",
    "\n",
    "location_counts = {key: 0 for key in location_options.keys()}\n",
    "time_counts = {key: 0 for key in time_options.keys()}\n",
    "n_incidents = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row['bullying_location']):\n",
    "        locations = [loc.strip() for loc in row['bullying_location'].split(',')]\n",
    "        for loc in locations:\n",
    "            for key, val in location_options.items():\n",
    "                if loc == val:\n",
    "                    location_counts[key] += 1\n",
    "                    n_incidents += 1\n",
    "    if pd.notna(row['bullying_time']):\n",
    "        times = [time.strip() for time in row['bullying_time'].split(',')]\n",
    "        for time in times:\n",
    "            for key, val in time_options.items():\n",
    "                if time == val:\n",
    "                    time_counts[key] += 1\n",
    "\n",
    "template = template.replace(\"{n_incidents}\", str(n_incidents))\n",
    "\n",
    "# Top locations\n",
    "sorted_locations = sorted(location_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_location_1, count_loc_1 = sorted_locations[0]\n",
    "top_location_2, count_loc_2 = sorted_locations[1]\n",
    "template = template.replace(\"{top_location_1}\", location_options[top_location_1])\n",
    "template = template.replace(\"{count_loc_1}\", str(count_loc_1))\n",
    "template = template.replace(\"{top_location_2}\", location_options[top_location_2])\n",
    "template = template.replace(\"{count_loc_2}\", str(count_loc_2))\n",
    "\n",
    "# Top time\n",
    "sorted_times = sorted(time_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_time, top_time_count = sorted_times[0]\n",
    "pct_top_time = round((top_time_count / n_incidents) * 100, 1) if n_incidents > 0 else 0\n",
    "template = template.replace(\"{top_time}\", time_options[top_time])\n",
    "template = template.replace(\"{pct_top_time}\", fmt(pct_top_time))\n",
    "\n",
    "# Heatmap plot\n",
    "location_labels = [location_options[key] for key in location_options.keys()]\n",
    "time_labels = [time_options[key] for key in time_options.keys()]\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Create empty matrix\n",
    "heatmap_data = pd.DataFrame(0.0, index=location_labels, columns=time_labels)\n",
    "\n",
    "# 2. Fill data with \"Fractional Counting\" (weighting)\n",
    "for idx, row in df.iterrows():\n",
    "    # Check if answers exist\n",
    "    if pd.notna(row['bullying_location']) and pd.notna(row['bullying_time']):\n",
    "        # Create lists\n",
    "        locs = [l.strip() for l in row['bullying_location'].split(',')]\n",
    "        times = [t.strip() for t in row['bullying_time'].split(',')]\n",
    "\n",
    "        # Map to labels\n",
    "        valid_locs = [location_options[k] for k in location_options if location_options[k] in locs]\n",
    "        valid_times = [time_options[k] for k in time_options if time_options[k] in times]\n",
    "\n",
    "        if valid_locs and valid_times:\n",
    "            # WEIGHTING: The more checks, the less each individual field counts\n",
    "            # A student with 1 location/1 time gives 1 point.\n",
    "            # A student with 3 locations/2 times gives each field only 0.16 points (1/6).\n",
    "            weight = 1.0 / (len(valid_locs) * len(valid_times))\n",
    "\n",
    "            for loc_label in valid_locs:\n",
    "                for time_label in valid_times:\n",
    "                    heatmap_data.at[loc_label, time_label] += weight\n",
    "\n",
    "# Set combinations to 0 that logically make no sense\n",
    "# Way to school does not happen during class or break\n",
    "heatmap_data.at['Schulweg', 'W√§hrend des Unterrichts'] = 0\n",
    "heatmap_data.at['Schulweg', 'In den Pausen'] = 0\n",
    "\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "\n",
    "plt.ylabel('Ort der Vorf√§lle')\n",
    "plt.xlabel('Zeitpunkt der Vorf√§lle')\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_locations.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Perpetrator Origin and Group Size: Calculations and Replace in Template (5.2)\n",
    "\n",
    "perpetrator_counts = df['perpetrators_classmate'].value_counts(normalize=True) * 100\n",
    "pct_internal_perpetrators = round(perpetrator_counts.get('Ja', 0), 1)\n",
    "template = template.replace(\"{pct_internal_perpetrators}\", fmt(pct_internal_perpetrators))\n",
    "group_counts = df['perpetrator_count'].value_counts(normalize=True) * 100\n",
    "pct_group_bullying = round(group_counts[group_counts.index.isin(['Zwei bis vier Personen', 'Mehr als vier Personen', 'Mehr als die H√§lfte einer Klasse'])].sum(), 1)\n",
    "template = template.replace(\"{pct_group_bullying}\", fmt(pct_group_bullying))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Bully-Victims Analysis: Calculations and Venn Diagram (5.3)\n",
    "\n",
    "# Define victim and perpetrator conditions\n",
    "victim_conditions = (\n",
    "    (df['physical_violence_freq'].isin(['Monatlich', 'W√∂chentlich', 'Mehrmals pro Woche', 'T√§glich'])) |\n",
    "    (df['verbal_violence_freq'].isin(['Monatlich', 'W√∂chentlich', 'Mehrmals pro Woche', 'T√§glich'])) |\n",
    "    (df['cyberbullying_freq'].isin(['Monatlich', 'W√∂chentlich', 'Mehrmals pro Woche', 'T√§glich']))\n",
    ")\n",
    "\n",
    "perpetrator_conditions = (\n",
    "    (df['own_bullying_behavior'].isin(['Mehrfach im letzten Monat', 'Ungef√§hr einmal pro Woche', 'Mehrmals pro Woche']))\n",
    ")\n",
    "\n",
    "# Classify students\n",
    "df['is_victim'] = victim_conditions\n",
    "\n",
    "df['is_perpetrator'] = perpetrator_conditions\n",
    "\n",
    "# Calculate percentages\n",
    "n_students = len(df)\n",
    "n_pure_victims = len(df[(df['is_victim']) & (~df['is_perpetrator'])])\n",
    "n_pure_bullies = len(df[(~df['is_victim']) & (df['is_perpetrator'])])\n",
    "n_bully_victims = len(df[(df['is_victim']) & (df['is_perpetrator'])])\n",
    "\n",
    "pct_pure_victims = round((n_pure_victims / n_students) * 100, 1)\n",
    "pct_pure_bullies = round((n_pure_bullies / n_students) * 100, 1)\n",
    "pct_bully_victims = round((n_bully_victims / n_students) * 100, 1)\n",
    "\n",
    "template = template.replace(\"{pct_pure_victims}\", fmt(pct_pure_victims))\n",
    "template = template.replace(\"{pct_pure_bullies}\", fmt(pct_pure_bullies))\n",
    "template = template.replace(\"{pct_bully_victims}\", fmt(pct_bully_victims))\n",
    "\n",
    "# Venn diagram\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "# 1. Define the subsets\n",
    "# venn2 accepts a tuple of 3 integers: (Ab, aB, AB)\n",
    "# Ab = Set A (Victim) but not B = Pure Victims\n",
    "# aB = Set B (Perpetrator) but not A = Pure Bullies\n",
    "# AB = Intersection = Bully-Victims\n",
    "subsets = (n_pure_victims, n_pure_bullies, n_bully_victims)\n",
    "\n",
    "# 2. Create the figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# 3. Generate the diagram\n",
    "# 'set_labels' names the two primary circles\n",
    "v = venn2(subsets=subsets, set_labels=('Opfer', 'T√§ter'))\n",
    "\n",
    "# 4. Customizing Labels & Colors\n",
    "# Region '10': Pure Victims (Left Circle)\n",
    "if v.get_label_by_id('10'):\n",
    "    v.get_label_by_id('10').set_text(f\"Reine Opfer\\n{n_pure_victims}\\n({pct_pure_victims}%)\")\n",
    "    v.get_patch_by_id('10').set_color('skyblue')\n",
    "    v.get_patch_by_id('10').set_alpha(0.6)\n",
    "\n",
    "# Region '01': Pure Bullies (Right Circle)\n",
    "if v.get_label_by_id('01'):\n",
    "    v.get_label_by_id('01').set_text(f\"Reine T√§ter\\n{n_pure_bullies}\\n({pct_pure_bullies}%)\")\n",
    "    v.get_patch_by_id('01').set_color('salmon')\n",
    "    v.get_patch_by_id('01').set_alpha(0.6)\n",
    "\n",
    "# Region '11': Bully-Victims (Intersection)\n",
    "if v.get_label_by_id('11'):\n",
    "    v.get_label_by_id('11').set_text(f\"Bully-Victims\\n{n_bully_victims}\\n({pct_bully_victims}%)\")\n",
    "    v.get_patch_by_id('11').set_color('purple')\n",
    "    v.get_patch_by_id('11').set_alpha(0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_bully_victim_venn.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4391ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Bystander Gap: Calculations and Diagram (6.1)\n",
    "\n",
    "n_observers = len(df[['intervention_willingness', 'past_reaction_observation']].dropna())\n",
    "template = template.replace(\"{n_observers}\", fmt(n_observers))\n",
    "\n",
    "willingness_counts = df['intervention_willingness'].value_counts(normalize=True) * 100\n",
    "pct_willingness = round(willingness_counts[willingness_counts.index.isin([4, 5])].sum(), 1)\n",
    "template = template.replace(\"{pct_willingness}\", fmt(pct_willingness))\n",
    "\n",
    "actual_help_counts = df['past_reaction_observation'].str.contains(\"Ich habe versucht, dem Opfer direkt zu helfen.\", na=False).sum()\n",
    "pct_actual_help = round((actual_help_counts / n_observers) * 100, 1) if n_observers > 0 else 0\n",
    "template = template.replace(\"{pct_actual_help}\", fmt(pct_actual_help))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d76ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Reporting Behavior: Calculations and Diagram (6.2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "helping_contacts = {\n",
    "    \"counselor\": \"VertrauenslehrerIn\",\n",
    "    \"class_teacher\": \"KlassenlehrerIn\",\n",
    "    \"friends\": \"FreundInnen\",\n",
    "    \"family\": \"Eltern / Familie\",\n",
    "    \"helpline\": \"Kinder- und Jugendtelefon\",\n",
    "    \"other\": \"Andere\"\n",
    "}\n",
    "\n",
    "# Overall willingness to report\n",
    "overall_reporting = {key: 0 for key in helping_contacts.keys()}\n",
    "# Actual reporting by victims\n",
    "victim_reporting = {key: 0 for key in helping_contacts.keys()}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row['preferred_help_contact']):\n",
    "        contacts = [c.strip() for c in row['preferred_help_contact'].split(',')]\n",
    "        for contact in contacts:\n",
    "            for key, val in helping_contacts.items():\n",
    "                if contact == val:\n",
    "                    overall_reporting[key] += 1\n",
    "    if row['is_victim']:\n",
    "        if pd.notna(row['preferred_help_contact']):\n",
    "            contacts = [c.strip() for c in row['preferred_help_contact'].split(',')]\n",
    "            for contact in contacts:\n",
    "                for key, val in helping_contacts.items():\n",
    "                    if contact == val:\n",
    "                        victim_reporting[key] += 1\n",
    "\n",
    "n_victims = len(df[df['is_victim']])\n",
    "# Note: n_total needs to be defined from your original script context\n",
    "# If n_total is missing here, ensure it exists in your variable scope\n",
    "overall_reporting_pct = {key: round((count / num_total) * 100, 1) for key, count in overall_reporting.items()}\n",
    "victim_reporting_pct = {key: round((count / n_victims) * 100, 1) for key, count in victim_reporting.items()}\n",
    "\n",
    "# Prepare data\n",
    "reporting_df = pd.DataFrame({\n",
    "    'Gesamtheit': overall_reporting_pct,\n",
    "    'Tats√§chliche Opfer': victim_reporting_pct\n",
    "}).T\n",
    "\n",
    "\n",
    "# 1. Rename columns using the dictionary for a better legend\n",
    "reporting_df = reporting_df.rename(columns=helping_contacts)\n",
    "\n",
    "# Use a distinct color palette (6 colors for the 6 categories)\n",
    "colors = ['#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462']\n",
    "\n",
    "# 3. Plot\n",
    "ax = reporting_df.plot(\n",
    "    kind='bar', \n",
    "    figsize=(12, 7), \n",
    "    color=colors, \n",
    "    edgecolor='white', \n",
    "    linewidth=1,\n",
    "    width=0.8\n",
    ")\n",
    "\n",
    "# 4. Styling and Annotations\n",
    "plt.ylabel('Anteil (%)', fontsize=12)\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=0, fontsize=11) # Horizontal labels are easier to read\n",
    "\n",
    "# Add gridlines behind bars\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.5, color='gray')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Remove top and right borders (spines) for a cleaner look\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add percentage numbers on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=9)\n",
    "\n",
    "# Improve Legend placement (outside the chart)\n",
    "plt.legend(\n",
    "    title='Kontaktperson', \n",
    "    bbox_to_anchor=(1.02, 1), \n",
    "    loc='upper left', \n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_reporting_behavior.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Percentage of victims that visit counselors\n",
    "\n",
    "pct_victims_counselor = victim_reporting_pct.get('counselor', 0)\n",
    "template = template.replace(\"{pct_victims_trust_teacher}\", fmt(pct_victims_counselor))\n",
    "\n",
    "# Percentage of victims that don't seek help at all\n",
    "\n",
    "n_victims_no_help = 0\n",
    "for idx, row in df[df['is_victim']].iterrows():\n",
    "    if pd.isna(row['preferred_help_contact']) or row['preferred_help_contact'].strip() == \"\":\n",
    "        n_victims_no_help += 1\n",
    "\n",
    "pct_victims_no_help = round((n_victims_no_help / n_victims) * 100, 1) if n_victims > 0 else 0\n",
    "template = template.replace(\"{pct_victims_no_one}\", fmt(pct_victims_no_help))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abaa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Strategien der Gegenwehr: Calculations (6.3)\n",
    "\n",
    "defense_options = {\n",
    "    \"physical\": \"K√∂rperlich (Zur√ºckschlagen, Pr√ºgel)\",\n",
    "    \"verbal\": \"Verbal (Beleidigungen, Rufe)\",\n",
    "    \"friends\": \"Ich hole FreundInnen.\",\n",
    "    \"teachers\": \"Ich hole LehrerInnen.\",\n",
    "    \"withdrawal\": \"Ich ziehe mich zur√ºck/ gehe weg.\",\n",
    "    \"other\": \"Anderes\"\n",
    "}\n",
    "\n",
    "aggressive_reactions = ['physical', 'verbal']\n",
    "defensive_reactions = ['friends', 'teachers', 'withdrawal']\n",
    "\n",
    "n_defense_respondents = 0\n",
    "aggressive_count = 0\n",
    "defensive_count = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row['defense_reaction']):\n",
    "        n_defense_respondents += 1\n",
    "        reactions = [r.strip() for r in row['defense_reaction'].split(',')]\n",
    "        for reaction in reactions:\n",
    "            for key in defense_options.keys():\n",
    "                if reaction == defense_options[key]:\n",
    "                    if key in aggressive_reactions:\n",
    "                        aggressive_count += 1\n",
    "                    elif key in defensive_reactions:\n",
    "                        defensive_count += 1\n",
    "\n",
    "pct_defense_aggressive = round((aggressive_count / n_defense_respondents) * 100, 1) if n_defense_respondents > 0 else 0\n",
    "pct_defense_constructive = round((defensive_count / n_defense_respondents) * 100, 1) if n_defense_respondents > 0 else 0\n",
    "template = template.replace(\"{pct_defense_aggressive}\", fmt(pct_defense_aggressive))\n",
    "template = template.replace(\"{pct_defense_constructive}\", fmt(pct_defense_constructive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66086830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Tiefenanalyse: Heatmap & Treiber (Spearman) (7)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. Datenvorbereitung\n",
    "cols_of_interest = [\n",
    "    'friends_in_class', 'respect_in_class', 'liked_by_others', 'safety_in_class',\n",
    "    'like_school', 'teacher_fairness', 'teacher_trust', 'teacher_care',\n",
    "    'adult_listener_home', 'family_acceptance', 'intervention_willingness'\n",
    "]\n",
    "\n",
    "# Labels f√ºr die Grafik und den Text\n",
    "readable_labels = {\n",
    "    'friends_in_class': 'Freunde in der Klasse',\n",
    "    'respect_in_class': 'Respektvoller Umgang',\n",
    "    'liked_by_others': 'Soziale Akzeptanz',\n",
    "    'safety_in_class': 'Sicherheitsgef√ºhl',\n",
    "    'like_school': 'Schulzufriedenheit',\n",
    "    'teacher_fairness': 'Gerechtigkeit (Lehrer)',\n",
    "    'teacher_trust': 'Vertrauen (Lehrer)',\n",
    "    'teacher_care': 'Ernstgenommen werden',\n",
    "    'adult_listener_home': 'Zuh√∂rer zu Hause',\n",
    "    'family_acceptance': 'Familien-R√ºckhalt',\n",
    "    'intervention_willingness': 'Eingreif-Bereitschaft'\n",
    "}\n",
    "\n",
    "# Mapping sicherstellen (Text zu Zahlen)\n",
    "likert_map_corr = {\n",
    "    \"Stimme gar nicht zu\": 1, \"Stimme eher nicht zu\": 2, \"Teils/Teils\": 3,\n",
    "    \"Stimme eher zu\": 4, \"Stimme voll zu\": 5,\n",
    "    \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5\n",
    "}\n",
    "\n",
    "# Kopie erstellen und Datentypen bereinigen\n",
    "corr_df = df[cols_of_interest].copy()\n",
    "for col in cols_of_interest:\n",
    "    if corr_df[col].dtype == 'object':\n",
    "        corr_df[col] = corr_df[col].map(likert_map_corr)\n",
    "    corr_df[col] = pd.to_numeric(corr_df[col], errors='coerce')\n",
    "\n",
    "# 2. Berechnung (Spearman f√ºr ordinale Daten)\n",
    "corr_matrix = corr_df.corr(method='spearman')\n",
    "\n",
    "\n",
    "# 3. Plotten (Optimierte Heatmap: Kompakt ohne leere R√§nder)\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Maske erstellen (wie vorher)\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "plot_matrix = corr_matrix.iloc[1:, :-1]\n",
    "plot_mask = mask[1:, :-1]\n",
    "\n",
    "sns.heatmap(\n",
    "    plot_matrix,\n",
    "    mask=plot_mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    # Labels m√ºssen nun auch angepasst werden (wir nehmen die aus der getrimmten Matrix)\n",
    "    xticklabels=[readable_labels.get(c, c) for c in plot_matrix.columns],\n",
    "    yticklabels=[readable_labels.get(c, c) for c in plot_matrix.index],\n",
    "    cbar_kws={'shrink': .7},\n",
    "    square=True,\n",
    "    linewidths=.5\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(fontsize=9)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('img/chart_protective_factors.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# 4. Text-Logik: Treiber-Analyse\n",
    "target_var = 'like_school'\n",
    "insert_text = \"keine ausreichenden Daten\"\n",
    "\n",
    "if target_var in corr_matrix.columns:\n",
    "    # H√∂chste Korrelation zur Schulzufriedenheit finden (ohne sich selbst)\n",
    "    drivers = corr_matrix[target_var].drop(target_var)\n",
    "    \n",
    "    # NaN Werte entfernen, falls vorhanden, um Fehler bei idxmax zu vermeiden\n",
    "    drivers = drivers.dropna()\n",
    "    \n",
    "    if not drivers.empty:\n",
    "        best_driver_col = drivers.abs().idxmax()\n",
    "        best_val = drivers[best_driver_col]\n",
    "        best_driver_name = readable_labels.get(best_driver_col, best_driver_col)\n",
    "\n",
    "        # Logik f√ºr Textausgabe\n",
    "        if abs(best_val) < 0.2:\n",
    "            insert_text = \"kein einzelner Faktor\"\n",
    "        else:\n",
    "            insert_text = f\"{best_driver_name} (Korrelation r={fmt(best_val, 2)})\"\n",
    "\n",
    "# 5. Template anpassen\n",
    "# Hinweis: Stellen Sie sicher, dass 'template' vorher definiert wurde\n",
    "if 'template' in locals():\n",
    "    template = template.replace(\"{strongest_protective_factor}\", insert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifizierte Risikogruppe (Cluster 2): 10 Sch√ºler (10.6%)\n"
     ]
    }
   ],
   "source": [
    "# @title Clusteranalyse: Risikogruppen identifizieren (8.1)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Feature-Auswahl\n",
    "features_likert = ['friends_in_class', 'teacher_care', 'family_acceptance', \n",
    "                   'teacher_trust', 'teacher_fairness', 'like_school', \n",
    "                   'safety_in_class']\n",
    "features_freq = ['physical_violence_freq', 'verbal_violence_freq', \n",
    "                 'cyberbullying_freq']\n",
    "\n",
    "# Mapping f√ºr Frequenzen vorbereiten\n",
    "freq_map = {\n",
    "    \"Nie\": 0, \"Selten\": 1, \"Einmal\": 1, \"Monatlich\": 2, \n",
    "    \"Mehrfach im letzten Monat\": 2, \"W√∂chentlich\": 3, \n",
    "    \"Ungef√§hr einmal pro Woche\": 3, \"Mehrmals pro Woche\": 4, \"T√§glich\": 5\n",
    "}\n",
    "\n",
    "# 2. Datenaufbereitung f√ºr ML\n",
    "df_ml = df.copy()\n",
    "\n",
    "for col in features_freq:\n",
    "    # Umwandlung Text -> Zahl (unbekannte Texte werden zu NaN)\n",
    "    df_ml[col] = df_ml[col].map(freq_map)\n",
    "    # Auff√ºllen von NaN (auch durch Mapping entstandene) mit 0\n",
    "    df_ml[col] = df_ml[col].fillna(0)\n",
    "\n",
    "imputer_likert = SimpleImputer(strategy='median')\n",
    "\n",
    "df_ml[features_likert] = pd.DataFrame(\n",
    "    imputer_likert.fit_transform(df_ml[features_likert]),\n",
    "    columns=features_likert,\n",
    "    index=df_ml.index \n",
    ")\n",
    "\n",
    "# Scaling (wie im Original)\n",
    "scaler = StandardScaler()\n",
    "X = df_ml[features_likert + features_freq]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 4. R√ºckrechnung der Indizes\n",
    "df['score_victim'] = df_ml[features_freq].sum(axis=1)\n",
    "df['score_support'] = df_ml[['friends_in_class', 'teacher_care', 'family_acceptance']].sum(axis=1)\n",
    "\n",
    "# 5. Die Risikogruppe identifizieren\n",
    "cluster_profiles = df.groupby('cluster')[['score_victim', 'score_support']].mean()\n",
    "risk_cluster_id = cluster_profiles.sort_values(by='score_victim', ascending=False).index[0]\n",
    "\n",
    "# Statistiken f√ºr den Bericht\n",
    "n_risk_cluster = len(df[df['cluster'] == risk_cluster_id])\n",
    "pct_risk_cluster = round((n_risk_cluster / len(df)) * 100, 1)\n",
    "\n",
    "template = template.replace(\"{n_risk_cluster}\", str(n_risk_cluster))\n",
    "template = template.replace(\"{pct_risk_cluster}\", fmt(pct_risk_cluster))\n",
    "\n",
    "print(f\"Identifizierte Risikogruppe (Cluster {risk_cluster_id}): {n_risk_cluster} Sch√ºler ({pct_risk_cluster}%)\")\n",
    "\n",
    "# --- NEU: Cluster-Labels generieren (Logik aus Block 8.2 √ºbernommen) ---\n",
    "# Wir ben√∂tigen die Mittelwerte der Features pro Cluster, um die Namen zuzuweisen\n",
    "# FIX: numeric_only=True hinzugef√ºgt, um Textspalten zu ignorieren\n",
    "naming_means = df_ml.groupby(df['cluster']).mean(numeric_only=True)\n",
    "cluster_labels = {}\n",
    "\n",
    "for cid, row in naming_means.iterrows():\n",
    "    # Berechnung der Scores f√ºr die Namenslogik\n",
    "    victim_score = row['physical_violence_freq'] + row['verbal_violence_freq']\n",
    "    \n",
    "    # Ensure 'teacher_trust' is used correctly (it is part of features_likert and thus numeric in df_ml)\n",
    "    trust_score = row['teacher_trust'] \n",
    "    \n",
    "    count = len(df[df['cluster'] == cid])\n",
    "    \n",
    "    # Die Logik:\n",
    "    if cid == risk_cluster_id:\n",
    "        label = f\"Risikogruppe (n={count})\"\n",
    "    elif trust_score < 3.2 and victim_score < 1.0:\n",
    "        label = f\"System-Kritiker (n={count})\"\n",
    "    else:\n",
    "        label = f\"Integrierte/Unauff√§llige (n={count})\"\n",
    "    \n",
    "    cluster_labels[cid] = label\n",
    "\n",
    "# Label dem DataFrame hinzuf√ºgen\n",
    "df['cluster_label'] = df['cluster'].map(cluster_labels)\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# 6. Visualisierung mit neuen Labels\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Optional: Farben manuell zuweisen, passend zu den Labels (Rot f√ºr Risiko)\n",
    "custom_palette = {}\n",
    "for label in df['cluster_label'].unique():\n",
    "    if \"Risiko\" in label:\n",
    "        custom_palette[label] = '#d62728' # Rot\n",
    "    elif \"Kritiker\" in label:\n",
    "        custom_palette[label] = '#ff7f0e' # Orange\n",
    "    else:\n",
    "        custom_palette[label] = '#2ca02c' # Gr√ºn\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='score_victim', \n",
    "    y='score_support', \n",
    "    hue='cluster_label',  \n",
    "    palette=custom_palette, \n",
    "    s=100,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Markiere die Risikogruppe (Zentrum)\n",
    "risk_center = cluster_profiles.loc[risk_cluster_id]\n",
    "plt.annotate(f'Risikogruppe\\n(n={n_risk_cluster})', \n",
    "             xy=(risk_center['score_victim'], risk_center['score_support']), \n",
    "             xytext=(risk_center['score_victim'], risk_center['score_support'] + 2),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=12, color='red', weight='bold')\n",
    "\n",
    "plt.xlabel('Belastung (Gewalterfahrungen)')\n",
    "plt.ylabel('Ressourcen (Sozialer R√ºckhalt)')\n",
    "plt.legend(title=\"Gruppe\", loc='upper right') \n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.savefig('img/chart_risk_clusters.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3923106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Zusatz: PCA-Visualisierung der Cluster (8.1/2)\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. PCA berechnen\n",
    "pca = PCA(n_components=2)\n",
    "# HIER LAG DER FEHLER: Wir nutzen 'X_scaled' statt 'df_scaled'\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 2. DataFrame f√ºr den Plot bauen\n",
    "df_pca = pd.DataFrame(data=pca_components, columns=['PC1', 'PC2'])\n",
    "# Wir √ºbernehmen Ihre sch√∂nen Labels aus dem vorherigen Schritt\n",
    "df_pca['Cluster'] = df['cluster_label']\n",
    "\n",
    "# 3. Plotten\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Wir nutzen exakt dieselben Farben wie in Ihrer Cluster-Grafik\n",
    "custom_palette = {}\n",
    "for label in df_pca['Cluster'].unique():\n",
    "    if \"Risiko\" in str(label):\n",
    "        custom_palette[label] = '#d62728' # Rot\n",
    "    elif \"Kritiker\" in str(label):\n",
    "        custom_palette[label] = '#ff7f0e' # Orange\n",
    "    else:\n",
    "        custom_palette[label] = '#2ca02c' # Gr√ºn\n",
    "\n",
    "sns.scatterplot(\n",
    "    x='PC1', y='PC2',\n",
    "    hue='Cluster',\n",
    "    data=df_pca,\n",
    "    palette=custom_palette,\n",
    "    s=100,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Beschriftung\n",
    "var = pca.explained_variance_ratio_\n",
    "plt.xlabel(f'Hauptkomponente 1 (Erkl√§rt {var[0]:.1%} der Varianz)')\n",
    "plt.ylabel(f'Hauptkomponente 2 (Erkl√§rt {var[1]:.1%} der Varianz)')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.savefig('img/chart_pca_clusters.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6643fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Detail-Analyse ALLER Cluster (Profil-Plot) (8.2)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Definition der Analyse-Dimensionen\n",
    "cols_to_analyze = {\n",
    "    'safety_in_class': \"Sicherheitsgef√ºhl\",\n",
    "    'teacher_trust': \"Vertrauen zu Lehrern\",     # Wichtig f√ºr \"Kritiker\"-Gruppe\n",
    "    'teacher_fairness': \"Gerechtigkeit\",\n",
    "    'friends_in_class': \"Freunde\",\n",
    "    'family_acceptance': \"R√ºckhalt Familie\",      # Wichtig f√ºr Risiko-Gruppe\n",
    "    'physical_violence_freq': \"K√∂rperliche Gewalt\",\n",
    "    'verbal_violence_freq': \"Verbale Gewalt\"\n",
    "}\n",
    "\n",
    "# Mapping sicherstellen\n",
    "freq_map_detail = {\"Nie\": 0, \"Selten\": 1, \"Monatlich\": 2, \"W√∂chentlich\": 3, \"Mehrmals pro Woche\": 4, \"T√§glich\": 5}\n",
    "analysis_df = df.copy()\n",
    "for col in cols_to_analyze:\n",
    "    if analysis_df[col].dtype == 'object':\n",
    "        analysis_df[col] = analysis_df[col].map(freq_map_detail).fillna(0)\n",
    "    else:\n",
    "        analysis_df[col] = analysis_df[col].fillna(0)\n",
    "\n",
    "# 2. Daten f√ºr den Plot vorbereiten (Gruppiert nach Cluster)\n",
    "# Wir berechnen den Mittelwert JEDES Clusters f√ºr JEDE Frage\n",
    "cluster_means = analysis_df.groupby('cluster')[list(cols_to_analyze.keys())].mean()\n",
    "\n",
    "# 3. Automatische Benennung der Cluster (f√ºr die Legende)\n",
    "# Wir versuchen, den Clustern lesbare Namen zu geben basierend auf ihren Daten\n",
    "cluster_labels = {}\n",
    "for cid, row in cluster_means.iterrows():\n",
    "    # Logik:\n",
    "    # Viel Gewalt (>0.5) = \"Risiko\"\n",
    "    # Wenig Gewalt + Wenig Lehrer-Vertrauen (<3.0) = \"Kritiker\"\n",
    "    # Sonst = \"Integrierte\"\n",
    "    victim_score = row['physical_violence_freq'] + row['verbal_violence_freq']\n",
    "    trust_score = row['teacher_trust']\n",
    "    \n",
    "    if cid == risk_cluster_id:\n",
    "        label = f\"Risikogruppe (n={len(analysis_df[analysis_df['cluster']==cid])})\"\n",
    "    elif trust_score < 3.2 and victim_score < 1.0: # Schwelle f√ºr Kritiker\n",
    "        label = f\"System-Kritiker (n={len(analysis_df[analysis_df['cluster']==cid])})\"\n",
    "    else:\n",
    "        label = f\"Integrierte/Unauff√§llige (n={len(analysis_df[analysis_df['cluster']==cid])})\"\n",
    "    cluster_labels[cid] = label\n",
    "\n",
    "# 4. Plotten (Multi-Line Chart)\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Farben definieren (Risiko immer Rot, Rest dynamisch)\n",
    "palette = sns.color_palette(\"deep\", n_colors=len(cluster_means))\n",
    "# Wir wollen, dass das Risikocluster rot ist. \n",
    "# Einfacher Hack: Wir plotten einfach Linien und setzen Farbe manuell.\n",
    "\n",
    "for i, (cid, row) in enumerate(cluster_means.iterrows()):\n",
    "    label = cluster_labels[cid]\n",
    "    \n",
    "    # Style-Logik\n",
    "    if cid == risk_cluster_id:\n",
    "        color = '#d62728' # Rot\n",
    "        linewidth = 3\n",
    "        zorder = 10 # Nach vorne\n",
    "        marker = 'o'\n",
    "    elif \"Kritiker\" in label:\n",
    "        color = '#ff7f0e' # Orange\n",
    "        linewidth = 2\n",
    "        zorder = 5\n",
    "        marker = 's'\n",
    "    else:\n",
    "        color = '#2ca02c' # Gr√ºn\n",
    "        linewidth = 2\n",
    "        zorder = 1\n",
    "        marker = '^'\n",
    "\n",
    "    plt.plot(\n",
    "        range(len(cols_to_analyze)), \n",
    "        row, \n",
    "        marker=marker, \n",
    "        linewidth=linewidth, \n",
    "        color=color, \n",
    "        label=label,\n",
    "        zorder=zorder\n",
    "    )\n",
    "\n",
    "    # Werte beschriften (nur bei Risiko und Kritikern, um Chaos zu vermeiden)\n",
    "    if cid == risk_cluster_id or \"Kritiker\" in label:\n",
    "        for idx, val in enumerate(row):\n",
    "            plt.text(idx, val + 0.15, f\"{val:.1f}\", ha='center', color=color, fontweight='bold', fontsize=9)\n",
    "\n",
    "# Finish Setup\n",
    "plt.xticks(range(len(cols_to_analyze)), list(cols_to_analyze.values()), rotation=15)\n",
    "plt.ylabel('Durchschnittlicher Score (0-5)')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('img/chart_risk_profile.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1437151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Radar-Chart der Risikogruppe (8.2/2)\n",
    "\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "relevant_cols = list(cols_to_analyze.keys())\n",
    "\n",
    "# 1. Calculate Mean for Risk Group\n",
    "means_risk = analysis_df[analysis_df['cluster'] == risk_cluster_id][relevant_cols].mean()\n",
    "\n",
    "# 2. Calculate Mean for the Rest (Comparison Group)\n",
    "means_rest = analysis_df[analysis_df['cluster'] != risk_cluster_id][relevant_cols].mean()\n",
    "# -------------------------------------\n",
    "\n",
    "# 1. Prepare Data\n",
    "categories = list(cols_to_analyze.values())\n",
    "N = len(categories)\n",
    "\n",
    "# Values (Close the loop by repeating the first value at the end)\n",
    "values_risk = means_risk.tolist()\n",
    "values_risk += values_risk[:1]\n",
    "\n",
    "values_rest = means_rest.tolist()\n",
    "values_rest += values_rest[:1]\n",
    "\n",
    "# Calculate angles\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Start first axis at the top\n",
    "ax.set_theta_offset(pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Axis labels\n",
    "plt.xticks(angles[:-1], categories)\n",
    "\n",
    "# Y-Axis labels (keep small)\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([1, 2, 3, 4, 5], [\"1\", \"2\", \"3\", \"4\", \"5\"], color=\"grey\", size=7)\n",
    "plt.ylim(0, 5.5) # Assumption: Max Score is approx 5\n",
    "\n",
    "# Plot Risk Group\n",
    "ax.plot(angles, values_risk, linewidth=2, linestyle='solid', label='Risikogruppe', color='red')\n",
    "ax.fill(angles, values_risk, 'red', alpha=0.25)\n",
    "\n",
    "# Plot Average/Rest\n",
    "ax.plot(angles, values_rest, linewidth=2, linestyle='solid', label='Durchschnitt (Rest)', color='blue')\n",
    "ax.fill(angles, values_rest, 'blue', alpha=0.1)\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_risk_radar.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35cf013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Motives & Backgrounds: Perception vs. Self-Image: Calculations and Diagram (9)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Definition of options (Separated by question)\n",
    "options_perception = {\n",
    "    \"money_material\": \"Geld oder materielle Dinge\",\n",
    "    \"clothing\": \"Kleidung\",\n",
    "    \"appearance\": \"Aussehen / K√∂rperform\",\n",
    "    \"behavior\": \"Verhalten\",\n",
    "    \"rivalry\": \"Rivalit√§t / Konkurrenz\",\n",
    "    \"background_religion\": \"Herkunft / Religion / Hautfarbe\",\n",
    "    \"other\": \"Anderes\"\n",
    "}\n",
    "\n",
    "options_behavior = {\n",
    "    \"anger\": \"Aus Wut\",\n",
    "    \"distress\": \"Aus Not\",\n",
    "    \"fun\": \"Aus Spa√ü\",\n",
    "    \"retaliation\": \"Weil ich selbst ge√§rgert wurde\",\n",
    "    \"other\": \"Sonstiges\"\n",
    "}\n",
    "\n",
    "# 2. Evaluation: Perceived Motives (Q35)\n",
    "counts_perception = {txt: 0 for txt in options_perception.values()}\n",
    "n_perception = 0\n",
    "\n",
    "# Filter only rows that contain an answer\n",
    "valid_perception = df['bullying_motives_perception'].dropna()\n",
    "n_perception = len(valid_perception)\n",
    "\n",
    "for response in valid_perception:\n",
    "    # Split at comma if multiple choice is present as string\n",
    "    motives = [m.strip() for m in str(response).split(',')]\n",
    "    for motive in motives:\n",
    "        if motive in counts_perception:\n",
    "            counts_perception[motive] += 1\n",
    "\n",
    "# Percentage calculation Perception\n",
    "percents_perception = {k: round((v / n_perception * 100), 1) if n_perception > 0 else 0 \n",
    "                       for k, v in counts_perception.items()}\n",
    "\n",
    "# 3. Evaluation: Own Motives (Perpetrator) (Q41)\n",
    "counts_behavior = {txt: 0 for txt in options_behavior.values()}\n",
    "n_behavior = 0\n",
    "\n",
    "valid_behavior = df['reason_for_own_behavior'].dropna()\n",
    "n_behavior = len(valid_behavior)\n",
    "\n",
    "for response in valid_behavior:\n",
    "    motives = [m.strip() for m in str(response).split(',')]\n",
    "    for motive in motives:\n",
    "        # Check against values here, as the CSV probably contains the text\n",
    "        if motive in counts_behavior:\n",
    "            counts_behavior[motive] += 1\n",
    "\n",
    "# Percentage calculation Behavior\n",
    "percents_behavior = {k: round((v / n_behavior * 100), 1) if n_behavior > 0 else 0 \n",
    "                     for k, v in counts_behavior.items()}\n",
    "\n",
    "# 4. Plotting (Two subplots side by side)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7), sharey=True)\n",
    "\n",
    "# --- Plot 1: Perception ---\n",
    "labels_1 = list(percents_perception.keys())\n",
    "values_1 = list(percents_perception.values())\n",
    "x_pos_1 = np.arange(len(labels_1)) # Create explicit positions\n",
    "\n",
    "# Plot bars (use x_pos instead of labels for x-axis)\n",
    "bars1 = ax1.bar(x_pos_1, values_1, color='lightblue', edgecolor='black')\n",
    "\n",
    "ax1.set_title(f'Warum denkst du, mobben Sch√ºler? (Wahrnehmung)\\nn={n_perception}')\n",
    "ax1.set_ylabel('Anteil der Befragten (%)')\n",
    "\n",
    "# FIX: Set positions (Locator) first, then labels (Formatter)\n",
    "ax1.set_xticks(x_pos_1)\n",
    "ax1.set_xticklabels(labels_1, rotation=45, ha='right')\n",
    "\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Write values above bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height}%',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3), textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "# --- Plot 2: Perpetrator Statements ---\n",
    "labels_2 = list(percents_behavior.keys())\n",
    "values_2 = list(percents_behavior.values())\n",
    "x_pos_2 = np.arange(len(labels_2)) # Create explicit positions\n",
    "\n",
    "bars2 = ax2.bar(x_pos_2, values_2, color='lightcoral', edgecolor='black')\n",
    "\n",
    "ax2.set_title(f'Warum hast du das getan? (Selbstauskunft T√§ter)\\nn={n_behavior}')\n",
    "\n",
    "# FIX: Set positions (Locator) first, then labels (Formatter)\n",
    "ax2.set_xticks(x_pos_2)\n",
    "ax2.set_xticklabels(labels_2, rotation=45, ha='right')\n",
    "\n",
    "ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{height}%',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3), textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/chart_motives_compare.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Replace Placeholders in Template for Motives (9.1-9.2)\n",
    "\n",
    "# Percentage Perpetrators\n",
    "pct_perpetrators = round((n_behavior / num_total) * 100, 1) if num_total > 0 else 0\n",
    "template = template.replace(\"{pct_perpetrators}\", str(pct_perpetrators))\n",
    "\n",
    "# Perceived motives top 2\n",
    "sorted_perceived = sorted(percents_perception.items(), key=lambda x: x[1], reverse=True)\n",
    "top_motive_perceived_1, pct_motive_perceived_1 = sorted_perceived[0]\n",
    "top_motive_perceived_2, pct_motive_perceived_2 = sorted_perceived[1]\n",
    "template = template.replace(\"{top_motive_perceived_1}\", top_motive_perceived_1)\n",
    "template = template.replace(\"{pct_motive_perceived_1}\", fmt(pct_motive_perceived_1))\n",
    "template = template.replace(\"{top_motive_perceived_2}\", top_motive_perceived_2)\n",
    "template = template.replace(\"{pct_motive_perceived_2}\", fmt(pct_motive_perceived_2))\n",
    "\n",
    "# Actual motives top 2\n",
    "sorted_actual = sorted(percents_behavior.items(), key=lambda x: x[1], reverse=True)\n",
    "top_motive_actual_1, pct_motive_actual_1 = sorted_actual[0]\n",
    "top_motive_actual_2, pct_motive_actual_2 = sorted_actual[1]\n",
    "template = template.replace(\"{top_motive_actual_1}\", top_motive_actual_1)\n",
    "template = template.replace(\"{pct_motive_actual_1}\", fmt(pct_motive_actual_1))\n",
    "template = template.replace(\"{top_motive_actual_2}\", top_motive_actual_2)\n",
    "template = template.replace(\"{pct_motive_actual_2}\", fmt(pct_motive_actual_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81801b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nicht gen√ºgend Daten f√ºr Trend-Analyse (nur 1 Jahr). Erzeuge leere Platzhalter.\n"
     ]
    }
   ],
   "source": [
    "#@title Trend-Analyse & Diagramme generieren (10)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Aktuelle Daten in das gleiche Format bringen wie die Historie\n",
    "# (Wir greifen auf die Variablen zu, die Sie im Notebook berechnet haben)\n",
    "current_data_point = {\n",
    "    \"meta\": {\"school_year\": school_year},\n",
    "    \"violence_prevalence_global\": {\n",
    "        \"percent_physical_any\": pct_physical_any,\n",
    "        \"percent_verbal_any\": pct_verbal_any,\n",
    "        \"percent_cyber_any\": pct_cyber_any\n",
    "    },\n",
    "    \"climate_and_safety\": {\n",
    "        \"percent_safety_high\": pct_safety_high\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Liste kombinieren\n",
    "all_years = history_data + [current_data_point]\n",
    "\n",
    "# 3. Daten f√ºr Plot vorbereiten\n",
    "trend_rows = []\n",
    "for entry in all_years:\n",
    "    sy = entry['meta']['school_year']\n",
    "    v = entry.get('violence_prevalence_global', {})\n",
    "    s = entry.get('climate_and_safety', {})\n",
    "    \n",
    "    trend_rows.append({\n",
    "        \"Schuljahr\": sy,\n",
    "        \"K√∂rperliche Gewalt\": v.get('percent_physical_any', 0),\n",
    "        \"Verbale Gewalt\": v.get('percent_verbal_any', 0),\n",
    "        \"Cybermobbing\": v.get('percent_cyber_any', 0),\n",
    "        \"Hohes Sicherheitsgef√ºhl\": s.get('percent_safety_high', 0)\n",
    "    })\n",
    "\n",
    "df_trend = pd.DataFrame(trend_rows)\n",
    "\n",
    "# Nach Schuljahr sortieren (wichtig!)\n",
    "df_trend.sort_values('Schuljahr', inplace=True)\n",
    "\n",
    "# --- Check: Haben wir genug Daten? ---\n",
    "if len(df_trend) > 1:\n",
    "    # A) Gewalt-Trend Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_trend['Schuljahr'], df_trend['K√∂rperliche Gewalt'], marker='o', label='K√∂rperlich')\n",
    "    plt.plot(df_trend['Schuljahr'], df_trend['Verbale Gewalt'], marker='o', label='Verbal')\n",
    "    plt.plot(df_trend['Schuljahr'], df_trend['Cybermobbing'], marker='o', label='Digital')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.savefig('img/chart_trend_violence.png')\n",
    "    plt.close()\n",
    "\n",
    "    # B) Sicherheits-Trend Plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df_trend['Schuljahr'], df_trend['Hohes Sicherheitsgef√ºhl'], marker='s', color='green', linestyle='--')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True)\n",
    "    plt.savefig('img/chart_trend_safety.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Texte generieren (einfacher Vergleich zum Vorjahr)\n",
    "    # (Hier k√∂nnten Sie komplexe Logik einf√ºgen, wir machen es simpel)\n",
    "    last_year = df_trend.iloc[-2]\n",
    "    this_year = df_trend.iloc[-1]\n",
    "    \n",
    "    def get_trend_text(old, new):\n",
    "        diff = new - old\n",
    "        if abs(diff) < 2: return \"Unver√§ndert\"\n",
    "        return f\"{'Gestiegen' if diff > 0 else 'Gesunken'} ({fmt(diff)}%)\"\n",
    "\n",
    "    template = template.replace(\"{trend_text_phys}\", get_trend_text(last_year['K√∂rperliche Gewalt'], this_year['K√∂rperliche Gewalt']))\n",
    "    template = template.replace(\"{trend_text_verb}\", get_trend_text(last_year['Verbale Gewalt'], this_year['Verbale Gewalt']))\n",
    "    template = template.replace(\"{trend_text_cyber}\", get_trend_text(last_year['Cybermobbing'], this_year['Cybermobbing']))\n",
    "\n",
    "else:\n",
    "    # Fallback: Nur 1 Jahr vorhanden\n",
    "    print(\"Nicht gen√ºgend Daten f√ºr Trend-Analyse (nur 1 Jahr). Erzeuge leere Platzhalter.\")\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.text(0.5, 0.5, \"Keine Vorjahresdaten\", ha='center', va='center', fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('img/chart_trend_violence.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.text(0.5, 0.5, \"Keine Vorjahresdaten\", ha='center', va='center', fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('img/chart_trend_safety.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    template = template.replace(\"{trend_text_phys}\", \"Keine Vergleichsdaten\")\n",
    "    template = template.replace(\"{trend_text_verb}\", \"Keine Vergleichsdaten\")\n",
    "    template = template.replace(\"{trend_text_cyber}\", \"Keine Vergleichsdaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d6eae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Freitexte (verbessert) erfolgreich extrahiert.\n"
     ]
    }
   ],
   "source": [
    "#@title Extract Free Text (Other) (A.1-A.4)\n",
    "\n",
    "import re\n",
    "\n",
    "# 1. Helper: Clean text to prevent LaTeX errors\n",
    "def clean_text_for_report(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    # Escape characters that break LaTeX\n",
    "    chars = {\n",
    "        \"&\": r\"\\&\",\n",
    "        \"%\": r\"\\%\",\n",
    "        \"$\": r\"\\$\",\n",
    "        \"_\": r\"\\_\",\n",
    "        \"#\": r\"\\#\",\n",
    "        \"{\": r\"\\{\",\n",
    "        \"}\": r\"\\}\",\n",
    "        # We also replace double spaces that might occur after removing options\n",
    "        \"  \": \" \" \n",
    "    }\n",
    "    for char, escaped in chars.items():\n",
    "        text = text.replace(char, escaped)\n",
    "    text = text.encode('latin-1', 'ignore').decode('latin-1')\n",
    "    return text.strip()\n",
    "\n",
    "# 2. Helper: Get standard options\n",
    "def get_standard_options(survey_data, question_id):\n",
    "    \"\"\"Returns a list of the standard 'long' text options.\"\"\"\n",
    "    for q in survey_data:\n",
    "        if q['short_id'] == question_id:\n",
    "            if 'options' in q:\n",
    "                opts = []\n",
    "                for opt in q['options']:\n",
    "                    if isinstance(opt, dict):\n",
    "                        opts.append(opt['long'])\n",
    "                    else:\n",
    "                        opts.append(opt)\n",
    "                return opts\n",
    "    return []\n",
    "\n",
    "# 3. Main Logic: Subtract options instead of splitting\n",
    "def extract_freetext_answers(df, col_name, standard_options):\n",
    "    if col_name not in df.columns:\n",
    "        return \"Keine Daten vorhanden.\"\n",
    "\n",
    "    custom_answers = []\n",
    "    \n",
    "    # Sort options by length (longest first). \n",
    "    # This prevents partial removal (e.g. removing \"Male\" from \"Malevolent\")\n",
    "    # and ensures precise matching.\n",
    "    sorted_options = sorted(standard_options, key=len, reverse=True)\n",
    "    \n",
    "    # Common labels for \"Other\" that usually precede the text in CSVs\n",
    "    # We remove these labels to clean up the result.\n",
    "    remove_labels = [\"Anderes\", \"Sonstiges\", \"Other\", \"nan\", \"None\", \"Eigenes\", \"Begr√ºndung\"]\n",
    "\n",
    "    for entry in df[col_name].dropna():\n",
    "        # Work with a fresh string copy\n",
    "        text = str(entry)\n",
    "        \n",
    "        # A. REMOVE STANDARD OPTIONS\n",
    "        # We iterate through every possible checkbox answer for this question\n",
    "        # and remove it from the student's answer string.\n",
    "        for opt in sorted_options:\n",
    "            if opt in text:\n",
    "                text = text.replace(opt, \"\")\n",
    "\n",
    "        # B. CLEANUP ARTIFACTS\n",
    "        # 1. Remove the \"Other\" labels (case insensitive)\n",
    "        for label in remove_labels:\n",
    "            # We use regex to match whole words to avoid removing parts of user words\n",
    "            pattern = re.compile(re.escape(label), re.IGNORECASE)\n",
    "            text = pattern.sub(\"\", text)\n",
    "\n",
    "        # 2. Cleanup leftover commas and whitespace\n",
    "        # (e.g., \"Option A, , My Text\" becomes \", , My Text\")\n",
    "        text = text.replace(r\",\", \" \") # Replace remaining commas with spaces to treat them as separators\n",
    "        text = re.sub(r'\\s+', ' ', text) # Merge multiple spaces into one\n",
    "        text = text.strip() # Remove start/end whitespace\n",
    "\n",
    "        # 3. Final Check\n",
    "        # If the user typed a comma in their sentence, it is preserved (mostly),\n",
    "        # but since we replaced commas with spaces in step B2 to clean up the CSV structure, \n",
    "        # we might lose grammatical commas. \n",
    "        # BETTER APPROACH FOR B2:\n",
    "        # Instead of replacing commas blindly, let's just strip leading non-alphanumeric chars.\n",
    "        \n",
    "        # Reset text from raw entry for a second pass with better logic:\n",
    "        text = str(entry)\n",
    "        for opt in sorted_options:\n",
    "            # Replace option with a unique placeholder that isn't a comma\n",
    "            text = text.replace(opt, \"\")\n",
    "            \n",
    "        # Remove labels\n",
    "        for label in remove_labels:\n",
    "            text = text.replace(label, \"\")\n",
    "            \n",
    "        # Now we likely have strings like: \", , , I felt sad, because...\"\n",
    "        # We use regex to remove leading/trailing punctuation (commas, spaces)\n",
    "        # ^[ ,;]+ matches commas or spaces at the START\n",
    "        text = re.sub(r'^[ ,;]+', '', text)\n",
    "        # [ ,;]+$ matches commas or spaces at the END\n",
    "        text = re.sub(r'[ ,;]+$', '', text)\n",
    "        \n",
    "        # If anything substantial is left (longer than 2 chars), it's a custom answer\n",
    "        if len(text) > 2:\n",
    "            cleaned = clean_text_for_report(text)\n",
    "            custom_answers.append(cleaned)\n",
    "\n",
    "    if not custom_answers:\n",
    "        return \"Keine Eintr√§ge.\"\n",
    "\n",
    "    # Deduplicate entries while keeping order\n",
    "    seen = set()\n",
    "    unique_answers = []\n",
    "    for ans in custom_answers:\n",
    "        if ans not in seen:\n",
    "            unique_answers.append(ans)\n",
    "            seen.add(ans)\n",
    "\n",
    "    return \"\\n    * \".join(unique_answers)\n",
    "\n",
    "# 4. Map Template Placeholders\n",
    "mappings = [\n",
    "    (\"{list_free_text_q16}\", \"physical_violence_type\"),\n",
    "    (\"{list_free_text_q19}\", \"verbal_violence_type\"),\n",
    "    (\"{list_free_text_q22}\", \"cyberbullying_type\"),\n",
    "    (\"{list_free_text_q26}\", \"defense_reaction\"),\n",
    "    (\"{list_free_text_q31}\", \"observer_feelings\"), \n",
    "    (\"{list_free_text_q32}\", \"past_reaction_observation\"),\n",
    "    (\"{list_free_text_q28}\", \"bullying_location\"),\n",
    "    (\"{list_free_text_q34}\", \"preferred_help_contact\"),\n",
    "    (\"{list_free_text_q35}\", \"bullying_motives_perception\"),\n",
    "    (\"{list_free_text_q41}\", \"reason_for_own_behavior\"),\n",
    "]\n",
    "\n",
    "# 5. Execute Replacement\n",
    "for template_key, col_name in mappings:\n",
    "    # Get standard options\n",
    "    std_opts = get_standard_options(survey, col_name)\n",
    "    \n",
    "    # Extract custom text\n",
    "    result_text = extract_freetext_answers(df, col_name, std_opts)\n",
    "    \n",
    "    # Replace in template\n",
    "    template = template.replace(template_key, result_text)\n",
    "\n",
    "print(\"‚úÖ Freitexte (verbessert) erfolgreich extrahiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f118e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Free Text: Generate LaTeX Table and Replace in Template (A.5)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Prepare Data\n",
    "open_texts = df[['class_level', 'open_feedback_text']].dropna().copy()\n",
    "\n",
    "# Sort logic\n",
    "open_texts['sort_num'] = open_texts['class_level'].str.extract(r'(\\d+)').astype(int)\n",
    "open_texts = open_texts.sort_values(by='sort_num')\n",
    "\n",
    "# 2. SANITIZE TEXT (Crucial for LaTeX)\n",
    "# LaTeX crashes if text contains & % $ _ without a backslash.\n",
    "def clean_for_latex(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    chars = {\n",
    "        \"&\": r\"\\&\",\n",
    "        \"%\": r\"\\%\",\n",
    "        \"$\": r\"\\$\",\n",
    "        \"_\": r\"\\_\",\n",
    "        \"#\": r\"\\#\",\n",
    "        \"{\": r\"\\{\",\n",
    "        \"}\": r\"\\}\",\n",
    "        \"\\n\": \" \" # Convert newlines to spaces to prevent table breaks\n",
    "    }\n",
    "    for char, escaped in chars.items():\n",
    "        text = text.replace(char, escaped)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "open_texts['class_level'] = open_texts['class_level'].apply(clean_for_latex)\n",
    "open_texts['open_feedback_text'] = open_texts['open_feedback_text'].apply(clean_for_latex)\n",
    "\n",
    "# 3. Manually Build the LaTeX String\n",
    "# We use 'longtable' for page breaks.\n",
    "# {|p{2cm}|p{12cm}|} defines vertical lines (|) and wrapped text width (p{...}).\n",
    "latex_rows = []\n",
    "\n",
    "# Start of table\n",
    "latex_rows.append(r\"```{=latex}\")  # RAW BLOCK START (Tells Pandoc: This is code, don't escape it!)\n",
    "latex_rows.append(r\"\\begin{longtable}{|p{2.5cm}|p{12cm}|}\") \n",
    "latex_rows.append(r\"\\hline\")\n",
    "latex_rows.append(r\"\\textbf{Klasse} & \\textbf{Freitext-Antwort} \\\\ \\hline\") # Header\n",
    "\n",
    "# Loop through data to add rows\n",
    "for _, row in open_texts.iterrows():\n",
    "    # formatting: col1 & col2 \\\\ \\hline\n",
    "    line = f\"{row['class_level']} & {row['open_feedback_text']} \\\\\\\\ \\\\hline\"\n",
    "    latex_rows.append(line)\n",
    "\n",
    "# End of table\n",
    "latex_rows.append(r\"\\end{longtable}\")\n",
    "latex_rows.append(r\"```\") # RAW BLOCK END\n",
    "\n",
    "# Join it all together\n",
    "final_latex_table = \"\\n\".join(latex_rows)\n",
    "\n",
    "template = template.replace(\"{open_text}\", final_latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e54315b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Free Text: Generate Cleaned Wordcloud (A.6)\n",
    "\n",
    "if IN_COLAB:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from wordcloud import WordCloud\n",
    "    import spacy\n",
    "    import pandas as pd\n",
    "\n",
    "    # 2. Setup Spacy Model\n",
    "    try:\n",
    "        nlp = spacy.load(\"de_core_news_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading German model...\")\n",
    "        from spacy.cli import download\n",
    "        download(\"de_core_news_sm\")\n",
    "        nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    # 3. Define Stopwords\n",
    "    # Merge default stopwords with school-specific noise words\n",
    "    stop_words = nlp.Defaults.stop_words.union({\n",
    "        \"dass\", \"muss\", \"soll\", \"immer\", \"mal\", \"schon\", \"w√§re\", \"w√ºrde\", \"halt\",\n",
    "        \"nein\", \"ja\", \"alles\", \"nichts\", \"wegen\", \"beim\", \"vom\", \"ganzen\",\n",
    "        \"finde\", \"f√§nde\", \"gut\", \"schlecht\", # Evaluative words often clutter clouds\n",
    "        \"schule\", \"klasse\" # Context words usually not needed in the cloud\n",
    "    })\n",
    "\n",
    "    def generate_clean_wordcloud(text_list):\n",
    "        \"\"\"\n",
    "        Generates a cleaned wordcloud from a list of strings using Spacy lemmatization.\n",
    "        \"\"\"\n",
    "        # Join all texts\n",
    "        full_text = \" \".join([str(t) for t in text_list])\n",
    "        \n",
    "        # Increase max_length if you have huge datasets (optional)\n",
    "        nlp.max_length = 2000000 \n",
    "        \n",
    "        # NLP Processing\n",
    "        doc = nlp(full_text)\n",
    "        \n",
    "        cleaned_tokens = []\n",
    "        for token in doc:\n",
    "            # Filter: Stopwords, Punctuation, Whitespace\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space:\n",
    "                # Check custom stopwords list\n",
    "                if token.text.lower() not in stop_words:\n",
    "                    # Filter by Part-of-Speech: Keep Nouns, Verbs, Adjectives\n",
    "                    if token.pos_ in ['NOUN', 'VERB', 'ADJ', 'PROPN']:\n",
    "                        cleaned_tokens.append(token.lemma_)\n",
    "\n",
    "        cleaned_text = \" \".join(cleaned_tokens)\n",
    "\n",
    "        if not cleaned_text:\n",
    "            print(\"Nach der Filterung sind keine W√∂rter √ºbrig geblieben.\")\n",
    "            return\n",
    "\n",
    "        # Generate Cloud\n",
    "        wordcloud = WordCloud(\n",
    "            width=1600, \n",
    "            height=800,\n",
    "            background_color=\"white\",\n",
    "            colormap=\"viridis\",\n",
    "            max_words=80,\n",
    "            collocations=False, # Avoids repeating phrases like \"good school\" as \"good school\" and \"school\"\n",
    "            min_word_length=3\n",
    "        ).generate(cleaned_text)\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad=0)\n",
    "        \n",
    "        # Save output\n",
    "        plt.savefig(\"img/wordcloud_feedback.png\")\n",
    "        plt.close()\n",
    "\n",
    "    raw_text_list = df.loc[open_texts.index, 'open_feedback_text'].dropna().tolist()\n",
    "\n",
    "    # Option B: Fallback (If 'df' is not available)\n",
    "    # If you only have 'open_texts', we must remove the LaTeX escape characters manually.\n",
    "    # raw_text_list = open_texts['open_feedback_text'].str.replace(r'\\\\', '', regex=True).tolist()\n",
    "\n",
    "    # Generate the Cloud\n",
    "    generate_clean_wordcloud(raw_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84e67ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Placeholder if wordcloud generation is skipped (A.6/2)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"img/wordcloud_feedback.png\"):\n",
    "    # 1. Setup the figure\n",
    "    # Aspect ratio matches a typical wordcloud (wide)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4), dpi=150)\n",
    "    \n",
    "    # Set limits to make drawing easier (coordinates 0 to 1)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off') # Hide the square box border\n",
    "\n",
    "    # 2. Define the Cloud Shape (Cluster of circles)\n",
    "    # We use a light grey color for the cloud body\n",
    "    cloud_color = '#ecf0f1'\n",
    "    \n",
    "    # Coordinates (x, y) and radius (r) for the \"fluffs\"\n",
    "    fluffs = [\n",
    "        (0.50, 0.50, 0.25), # Center Body\n",
    "        (0.35, 0.50, 0.20), # Left Lobe\n",
    "        (0.65, 0.50, 0.20), # Right Lobe\n",
    "        (0.42, 0.65, 0.18), # Top Left\n",
    "        (0.58, 0.65, 0.18), # Top Right\n",
    "    ]\n",
    "\n",
    "    for x, y, r in fluffs:\n",
    "        circle = patches.Circle((x, y), r, color=cloud_color, zorder=1)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    # 3. Draw the Sad Face\n",
    "    # Eyes (Small dark circles)\n",
    "    eye_left = patches.Circle((0.45, 0.55), 0.015, color='#7f8c8d', zorder=2)\n",
    "    eye_right = patches.Circle((0.55, 0.55), 0.015, color='#7f8c8d', zorder=2)\n",
    "    ax.add_patch(eye_left)\n",
    "    ax.add_patch(eye_right)\n",
    "\n",
    "    # Mouth (A curved line for a frown)\n",
    "    # We create a simple arc using a plotted line\n",
    "    x_mouth = np.linspace(0.46, 0.54, 50)\n",
    "    # Parabola equation for a frown: y = -a*(x-h)^2 + k\n",
    "    y_mouth = -1.5 * (x_mouth - 0.5)**2 + 0.50 \n",
    "    \n",
    "    ax.plot(x_mouth, y_mouth, color='#7f8c8d', linewidth=2, zorder=2)\n",
    "\n",
    "    # 4. Add the Text below the cloud\n",
    "    plt.text(\n",
    "        0.5, 0.15, \n",
    "        \"Die Generierung der Wortwolke \\nist nicht verf√ºgbar.\", \n",
    "        ha='center', \n",
    "        va='center', \n",
    "        fontsize=14, \n",
    "        color='#95a5a6', \n",
    "        fontweight='bold',\n",
    "        fontname='sans-serif'\n",
    "    )\n",
    "\n",
    "    # 5. Save\n",
    "    plt.savefig(\"img/wordcloud_feedback.png\", bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Feedback-Analyse, Diagramm & Text (inkl. Freitext)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import numpy as np\n",
    "\n",
    "feedback_section_md = \"\"\n",
    "\n",
    "if has_feedback:\n",
    "    # -----------------------------------------------------------\n",
    "    # 1. Datenvorbereitung (Quantitativ)\n",
    "    # -----------------------------------------------------------\n",
    "    questions_map = {\n",
    "        'Die Fragen waren klar und verst√§ndlich formuliert.': 'Verst√§ndlichkeit',\n",
    "        'Ich habe mich beim Beantworten sicher und anonym gef√ºhlt.': 'Sicherheitsgef√ºhl',\n",
    "        'Die angegebene Zeit (10 bis 20 Min.) war realistisch und hat f√ºr mich gepasst.': 'Zeitaufwand',\n",
    "        'Wie w√ºrdest du die Umsetzung des Fragebogens bewerten?': 'Gesamtumsetzung',\n",
    "        'Ich glaube, dass die Ergebnisse dieser Umfrage etwas an unserer Schule verbessern werden.': 'Glaube an Wirkung'\n",
    "    }\n",
    "    \n",
    "    # Sicherstellen, dass Daten numerisch sind\n",
    "    for col in questions_map.keys():\n",
    "        if col in df_feedback.columns:\n",
    "            df_feedback[col] = pd.to_numeric(df_feedback[col], errors='coerce')\n",
    "\n",
    "    n_feedback = len(df_feedback)\n",
    "\n",
    "    # Kennzahlen f√ºr Text\n",
    "    col_impact = 'Ich glaube, dass die Ergebnisse dieser Umfrage etwas an unserer Schule verbessern werden.'\n",
    "    mean_understanding = round(df_feedback['Die Fragen waren klar und verst√§ndlich formuliert.'].mean(), 1)\n",
    "    mean_safety = round(df_feedback['Ich habe mich beim Beantworten sicher und anonym gef√ºhlt.'].mean(), 1)\n",
    "    mean_impact = round(df_feedback[col_impact].mean(), 1)\n",
    "    \n",
    "    # Schutz vor Division durch Null, falls n_feedback sehr klein ist\n",
    "    if n_feedback > 0:\n",
    "        pct_skeptical = round(len(df_feedback[df_feedback[col_impact] <= 2]) / n_feedback * 100, 1)\n",
    "    else:\n",
    "        pct_skeptical = 0.0\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2. Diagramm erstellen (Diverging Bar Chart)\n",
    "    # -----------------------------------------------------------\n",
    "    category_counts = []\n",
    "    labels = []\n",
    "\n",
    "    for q_long, q_short in questions_map.items():\n",
    "        if q_long in df_feedback.columns:\n",
    "            counts = df_feedback[q_long].value_counts(normalize=True) * 100\n",
    "            neg = counts[counts.index.isin([1, 2])].sum()\n",
    "            neu = counts[counts.index.isin([3])].sum()\n",
    "            pos = counts[counts.index.isin([4, 5])].sum()\n",
    "            category_counts.append([neg, neu, pos])\n",
    "            labels.append(q_short)\n",
    "\n",
    "    if category_counts:\n",
    "        df_plot = pd.DataFrame(category_counts, columns=['Negativ (1-2)', 'Neutral (3)', 'Positiv (4-5)'], index=labels)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        df_plot.plot(kind='barh', stacked=True, color=['#e74c3c', '#f1c40f', '#2ecc71'], ax=ax, edgecolor='white')\n",
    "        \n",
    "        plt.xlabel('Anteil der Antworten (%)')\n",
    "        plt.xlim(0, 100)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        for c in ax.containers:\n",
    "            ax.bar_label(c, fmt='%.0f%%', label_type='center', color='black', fontsize=9)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('img/chart_feedback_overview.png', dpi=150)\n",
    "        plt.close()\n",
    "    else:\n",
    "        # Fallback, falls keine Daten vorhanden\n",
    "        plt.figure()\n",
    "        plt.text(0.5, 0.5, 'Keine Feedback-Daten', ha='center')\n",
    "        plt.savefig('img/chart_feedback_overview.png')\n",
    "        plt.close()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3. Dynamische Text-Logik (Quantitativ)\n",
    "    # -----------------------------------------------------------\n",
    "    # A) Prozess (B.1)\n",
    "    if mean_understanding >= 4.0 and mean_safety >= 4.0:\n",
    "        interp_b1 = \"Die √ºberwiegend positiven Werte (gr√ºne Balken) best√§tigen, dass die Erhebung verstanden wurde und das Sicherheitsgef√ºhl hoch war.\"\n",
    "    else:\n",
    "        interp_b1 = \"Die Bewertungen zeigen ein gemischtes Bild.\"\n",
    "\n",
    "    # B) Vertrauen (B.2)\n",
    "    if pct_skeptical >= 30.0:\n",
    "        label_b2 = \"Herausforderung\"\n",
    "        text_b2 = f\"Der Balken f√ºr 'Glaube an Wirkung' zeigt einen deutlichen Rot-Anteil: {fmt(pct_skeptical)} % der Befragten sind aktuell skeptisch.\"\n",
    "        recommendation_b2 = \"Sichtbare Folgema√ünahmen sind essenziell, um diesen Balken in Zukunft ins Gr√ºne zu verschieben.\"\n",
    "    elif pct_skeptical <= 15.0:\n",
    "        label_b2 = \"Positives Signal\"\n",
    "        text_b2 = f\"Auch beim 'Glauben an Wirkung' √ºberwiegt der gr√ºne Anteil. Nur {fmt(pct_skeptical)} % √§u√üern Zweifel.\"\n",
    "        recommendation_b2 = \"Eine gute Basis f√ºr die weitere Arbeit.\"\n",
    "    else:\n",
    "        label_b2 = \"Geteiltes Meinungsbild\"\n",
    "        text_b2 = f\"W√§hrend Technik und Sicherheit top bewertet werden, ist die Erwartungshaltung an die Folgen gemischt ({fmt(pct_skeptical)} % Skeptiker).\"\n",
    "        recommendation_b2 = \"Transparenz ist nun entscheidend.\"\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 4. Freitext-Antworten verarbeiten (NEU)\n",
    "    # -----------------------------------------------------------\n",
    "    col_open_feedback = \"Offenes Feedback zum Fragebogen\" # Spaltennamen ggf. anpassen\n",
    "    open_feedback_md = \"\"\n",
    "\n",
    "    if col_open_feedback in df_feedback.columns:\n",
    "        # Leere Eintr√§ge entfernen\n",
    "        comments = df_feedback[col_open_feedback].dropna().astype(str)\n",
    "        # Nur Eintr√§ge behalten, die l√§nger als 3 Zeichen sind (um \"Nein\" oder \"-\" zu filtern)\n",
    "        comments = [c for c in comments if len(c.strip()) > 3 and c.lower() not in ['nein', 'nichts', 'no', '-']]\n",
    "        \n",
    "        if comments:\n",
    "            open_feedback_md = \"## C.3 Offenes Feedback (O-T√∂ne)\\n\"\n",
    "            open_feedback_md += \"Zus√§tzlich zur Bewertung wurden folgende Kommentare hinterlassen:\\n\\n\"\n",
    "            for comment in comments:\n",
    "                # Zeilenumbr√ºche im Kommentar durch Leerzeichen ersetzen f√ºr sauberes Markdown\n",
    "                clean_comment = comment.replace('\\n', ' ')\n",
    "                open_feedback_md += f\"> \\\"{clean_comment}\\\"\\n\\n\"\n",
    "        else:\n",
    "            open_feedback_md = \"## C.3 Offenes Feedback\\nEs wurden keine spezifischen Textkommentare hinterlassen.\\n\"\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 5. Markdown zusammensetzen\n",
    "    # -----------------------------------------------------------\n",
    "    feedback_section_md = f\"\"\"\n",
    "# Anhang C: Meta-Evaluation (Qualit√§tssicherung)\n",
    "\n",
    "Um die Qualit√§t der Daten und das Vertrauen der Sch√ºlerschaft sicherzustellen, wurde im Anschluss an die Hauptumfrage eine separate Evaluation durchgef√ºhrt (n={n_feedback}).\n",
    "\n",
    "![Detailliertes Meinungsbild zur Umfrage](img/chart_feedback_overview.png)\n",
    "\n",
    "## C.1 Bewertung des Prozesses\n",
    "Die Sch√ºlerinnen und Sch√ºler bewerteten die technische und inhaltliche Umsetzung sehr differenziert:\n",
    "\n",
    "* **Verst√§ndlichkeit:** {fmt(mean_understanding)} / 5\n",
    "* **Gef√ºhlte Sicherheit & Anonymit√§t:** {fmt(mean_safety)} / 5\n",
    "\n",
    "**Einordnung:** {interp_b1}\n",
    "\n",
    "## C.2 Vertrauen in Konsequenzen\n",
    "Auf die Frage *\"{col_impact}\"* liegt der Durchschnittswert bei **{fmt(mean_impact)} / 5**.\n",
    "\n",
    "* **{label_b2}:** {text_b2}\n",
    "* **Fazit:** {recommendation_b2}\n",
    "\n",
    "{open_feedback_md}\n",
    "\"\"\"\n",
    "\n",
    "else:\n",
    "    feedback_section_md = \"\"\n",
    "\n",
    "template = template.replace(\"{feedback_section_placeholder}\", feedback_section_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbf3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title AI Abstract Generation (Optional)\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import ai\n",
    "\n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an expert educational data analyst summarizing a school report.\n",
    "\n",
    "YOUR TASK:\n",
    "Write a concise \"Abstract\" in German (max. 4 sentences).\n",
    "1. State clearly what this document is (Statusbericht based on n=... students).\n",
    "2. Mention the single most defining trend or conflict found in the data (e.g., the discrepancy between teacher perception and student reality).\n",
    "3. Do not list detailed statistics. Keep it high-level.\n",
    "\n",
    "FORMATTING:\n",
    "- Use standard Markdown.\n",
    "- One single paragraph.\n",
    "- No bullet points.\n",
    "- Objective, professional tone.\n",
    "\n",
    "HERE IS THE REPORT CONTENT:\n",
    "{template}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the summary\n",
    "    summary = ai.generate_text(\n",
    "        prompt,\n",
    "    )\n",
    "\n",
    "    md_summary = f\"\"\"\n",
    "# Zusammenfassung (KI-gest√ºtzt)\n",
    "**Wichtiger Hinweis**: *Der folgende Abschnitt wurde automatisch durch ein LLM (Large Language Model) generiert. Es kann zu Missinterpretationen oder Fehlern kommen.*\n",
    "\n",
    "{summary}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"M√∂chten Sie die folgende KI-generierte Zusammenfassung in den Bericht einf√ºgen?\\n\\n{md_summary}\")\n",
    "\n",
    "    own_text = input(\"Geben Sie 'j' ein, um zu best√§tigen, dr√ºcken Sie ENTER zum √ºberspringen oder f√ºgen Sie Ihren Text ein (Markdown): \")\n",
    "\n",
    "    if own_text.lower() == 'j':\n",
    "        # Insert the summary into the template\n",
    "        template = template.replace(\"{ai_abstract_section}\", md_summary)\n",
    "\n",
    "    else:\n",
    "        # User provided their own text\n",
    "        template = template.replace(\"{ai_abstract_section}\", own_text)\n",
    "\n",
    "\n",
    "else:\n",
    "    template = template.replace(\"{ai_abstract_section}\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ba44295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title AI Executive Summary Generation (Optional)\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import ai\n",
    "\n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a strategic consultant for school administration. You are provided with the raw content of a school report.\n",
    "\n",
    "YOUR TASK:\n",
    "Write a high-impact \"Executive Summary\" in German.\n",
    "1. Do NOT repeat the general study metadata (participant count, etc.) unless absolutely necessary for context.\n",
    "2. Focus on \"Strategic Insights\": Synthesize the data to highlight the biggest gaps (e.g., specific risk groups, dangerous locations, teacher blind spots).\n",
    "3. Connect findings to implications: Don't just say \"38% violence\"; explain that this indicates a systemic issue in specific grades.\n",
    "4. Conclude with a \"Call to Action\" summarizing the direction for the school management.\n",
    "\n",
    "FORMATTING:\n",
    "- Use standard Markdown.\n",
    "- No Title.\n",
    "- Structure exactly into these 3 subheadings (##):\n",
    "  ## Kernergebnisse & Risikolage\n",
    "  (Use bullet points here for the hardest facts/correlations)\n",
    "  ## Strategische Defizite\n",
    "  (Focus on what is missing, e.g., teacher intervention perception)\n",
    "  ## Priorisierte Handlungsfelder\n",
    "  (Synthesize the recommended next steps)\n",
    "- You have to always add a blank line between text and bullet points for proper Markdown rendering.\n",
    "\n",
    "HERE IS THE REPORT CONTENT:\n",
    "{template}\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the summary\n",
    "    summary = ai.generate_text(\n",
    "        prompt,\n",
    "    )\n",
    "\n",
    "    md_summary = f\"\"\"\n",
    "# Entscheidungsorientierte Zusammenfassung (KI-gest√ºtzt)\n",
    "**Wichtiger Hinweis**: *Der folgende Abschnitt wurde automatisch durch ein LLM (Large Language Model) generiert. Es kann zu Missinterpretationen oder Fehlern kommen.*\n",
    "\n",
    "{summary}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"M√∂chten Sie die folgende AI Executive Summary in den Bericht einf√ºgen?\\n\\n{md_summary}\")\n",
    "    own_text = input(\"Geben Sie 'j' ein, um zu best√§tigen, dr√ºcken Sie ENTER zum √ºberspringen oder f√ºgen Sie Ihren Text ein (Markdown): \")\n",
    "\n",
    "    if own_text.lower() == 'j':\n",
    "        # Insert the summary into the template\n",
    "        template = template.replace(\"{ai_executive_summary}\", md_summary)\n",
    "\n",
    "    else:\n",
    "        template = template.replace(\"{ai_executive_summary}\", own_text)\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    template = template.replace(\"{ai_executive_summary}\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72c9c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved to Auswertung_Ergebnisse_2025-2026.pdf\n"
     ]
    }
   ],
   "source": [
    "#@title Convert Markdown to PDF with Pandoc\n",
    "\n",
    "import pypandoc\n",
    "\n",
    "# You must specify the output filename and the format\n",
    "safe_school_year = school_year.replace(\"/\", \"-\")\n",
    "output_filename = f\"Auswertung_Ergebnisse_{safe_school_year}.pdf\"\n",
    "\n",
    "try:\n",
    "    pypandoc.convert_text(\n",
    "        template,\n",
    "        'pdf',\n",
    "        format='md',\n",
    "        outputfile=output_filename,\n",
    "        extra_args=['--pdf-engine=xelatex']  # <--- THIS IS THE FIX\n",
    "    )\n",
    "    print(f\"Success! Saved to {output_filename}\")\n",
    "except OSError as e:\n",
    "    print(\"Error: Pandoc not found. Please ensure Pandoc is installed on your system.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Conversion Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "124bda56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Master-Archiv erstellt! (1 Jahrg√§nge enthalten).\n",
      "Datei: Auswertung_Ergebnisse_2025-2026.pdf\n"
     ]
    }
   ],
   "source": [
    "#@title Save PDF with CUMULATIVE History (Master Archive)\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Hilfsfunktion: Pandas Series/DataFrame in dict umwandeln, falls vorhanden\n",
    "def serialize_pandas(obj):\n",
    "    if isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "        return json.loads(obj.to_json(orient='index'))\n",
    "    return str(obj)\n",
    "\n",
    "# 1. Sammeln aller Metriken (Erweitert um Granulardaten)\n",
    "calculation_dump = {\n",
    "    \"meta\": {\n",
    "        \"author\": author_name,\n",
    "        \"school_year\": school_year,\n",
    "        \"report_date\": date_today,\n",
    "        \"student_count_input\": student_count,\n",
    "        \"n_total_responses\": num_total,\n",
    "        \"response_rate_percent\": response_rate,\n",
    "        \"data_collection_period\": data_collection_period,\n",
    "        \"class_levels_range\": f\"{min_class_level} - {max_class_level}\"\n",
    "    },\n",
    "    \"demographics_detailed\": {\n",
    "        \"total_by_gender\": {\n",
    "            \"percent_female\": pct_female,\n",
    "            \"percent_male\": pct_male,\n",
    "            \"percent_diverse\": pct_diverse\n",
    "        },\n",
    "        # Speichert Verteilung pro Klasse (aus Cell 149)\n",
    "        \"distribution_per_grade\": serialize_pandas(demographics) \n",
    "    },\n",
    "    \"climate_and_safety\": {\n",
    "        \"percent_safety_high\": pct_safety_high,\n",
    "        \"percent_friends_low\": pct_friends_low,\n",
    "        \"mean_teacher_justice\": mean_teacher_justice,\n",
    "        \"mean_teacher_trust\": mean_teacher_trust,\n",
    "        \"mean_teacher_care\": mean_teacher_serious,\n",
    "        \"std_teacher_justice\": round(df['teacher_fairness'].std(), 2),\n",
    "        \"std_teacher_trust\": round(df['teacher_trust'].std(), 2),\n",
    "        \"std_safety\": round(df['safety_in_class'].std(), 2)\n",
    "    },\n",
    "    \"violence_prevalence_global\": {\n",
    "        \"percent_verbal_any\": pct_verbal_any,\n",
    "        \"percent_physical_any\": pct_physical_any,\n",
    "        \"percent_cyber_any\": pct_cyber_any,\n",
    "        \"percent_chronic\": pct_chronic,\n",
    "        \"peak_violence_class\": peak_violence_class\n",
    "    },\n",
    "    \n",
    "    \"violence_by_gender\": serialize_pandas(\n",
    "        df.groupby('gender')[['physical_violence_freq', 'verbal_violence_freq', 'cyberbullying_freq']].apply(\n",
    "            lambda x: pd.Series({\n",
    "                'physical': compute_violence_prevalence(pd.DataFrame(x), 'physical_violence_freq'),\n",
    "                'verbal': compute_violence_prevalence(pd.DataFrame(x), 'verbal_violence_freq'),\n",
    "                'cyber': compute_violence_prevalence(pd.DataFrame(x), 'cyberbullying_freq')\n",
    "            })\n",
    "        )\n",
    "    ),\n",
    "    \"context\": {\n",
    "        \"n_incidents_reported\": n_incidents,\n",
    "        \"top_locations\": {\n",
    "            top_location_1: count_loc_1,\n",
    "            top_location_2: count_loc_2\n",
    "        },\n",
    "        \"percent_internal_perpetrators\": pct_internal_perpetrators,\n",
    "        \"percent_group_bullying\": pct_group_bullying\n",
    "    },\n",
    "    \"risk_groups\": {\n",
    "        \"percent_bully_victims\": pct_bully_victims,\n",
    "        \"n_risk_cluster\": n_risk_cluster,\n",
    "        \"percent_risk_cluster\": pct_risk_cluster,\n",
    "        },\n",
    "    \"motives\": {\n",
    "        \"perceived_top_2\": {\n",
    "            top_motive_perceived_1: pct_motive_perceived_1,\n",
    "            top_motive_perceived_2: pct_motive_perceived_2\n",
    "        },\n",
    "        \"actual_top_2\": {\n",
    "            top_motive_actual_1: pct_motive_actual_1,\n",
    "            top_motive_actual_2: pct_motive_actual_2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "final_archive = history_data + [calculation_dump] \n",
    "\n",
    "# 2. JSON Encoding\n",
    "json_bytes = json.dumps(final_archive, ensure_ascii=False).encode('utf-8')\n",
    "\n",
    "# 3. An PDF anh√§ngen\n",
    "if os.path.exists(output_filename):\n",
    "    with open(output_filename, 'ab') as f:\n",
    "        f.write(b'\\n') \n",
    "        f.write(json_bytes)\n",
    "    print(f\"‚úÖ Master-Archiv erstellt! ({len(final_archive)} Jahrg√§nge enthalten).\")\n",
    "    print(f\"Datei: {output_filename}\")\n",
    "else:\n",
    "    print(\"Fehler: PDF nicht gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2d2841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Datei wurde lokal gespeichert unter: /home/johangrims/P/P/Mobbing/Auswertung_Ergebnisse_2025-2026.pdf\n"
     ]
    }
   ],
   "source": [
    "#@title Download File (Colab only)\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(f\"Starte Download von {output_filename}...\")\n",
    "    files.download(output_filename)\n",
    "else:\n",
    "    print(f\"Die Datei wurde lokal gespeichert unter: {os.path.abspath(output_filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79391189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download ZIP of Images (Colab only)\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Nur nachfragen, wenn auch Bilder da sind\n",
    "    if not os.path.exists('img') or not os.listdir('img'):\n",
    "         print(\"Keine Bilder im Ordner 'img' gefunden.\")\n",
    "    else:\n",
    "        confirm = input(\"M√∂chten Sie alle generierten Bilder (Diagramme, Wortwolke) als ZIP-Datei herunterladen? (j/n): \")\n",
    "\n",
    "        # Add description title to each image\n",
    "\n",
    "        images = [\n",
    "            'chart_demographics.png',\n",
    "            'chart_feedback_overview.png',\n",
    "            'chart_wellbeing.png',\n",
    "            'chart_violence_prevalence.png',\n",
    "            'chart_violence_by_age.png',\n",
    "            'chart_gender_violence.png',\n",
    "            'chart_locations.png',\n",
    "            'chart_bully_victim_venn.png',\n",
    "            'chart_reporting_behavior.png',\n",
    "            'chart_protective_factors.png',\n",
    "            'chart_risk_clusters.png',\n",
    "            'chart_pca_clusters.png',\n",
    "            'chart_risk_profile.png',\n",
    "            'chart_risk_radar.png',\n",
    "            'chart_motives_compare.png',\n",
    "            'chart_trend_violence.png',\n",
    "            'chart_trend_safety.png',\n",
    "            'wordcloud_feedback.png'\n",
    "        ]\n",
    "\n",
    "        descriptions = [\n",
    "            \"Demografische Verteilung\",\n",
    "            \"√úbersicht der Umfrage-Bewertungen\",\n",
    "            \"Wohlbefinden und Sicherheit\",\n",
    "            \"Pr√§valenz von Gewaltformen\",\n",
    "            \"Gewaltverlauf nach Klassenstufen\",\n",
    "            \"Gewaltverteilung nach Geschlecht\",\n",
    "            \"Heatmap: Tatorte und Zeiten\",\n",
    "            \"T√§ter-Opfer-Zyklus (Venn)\",\n",
    "            \"Meldeverhalten und Vertrauenspersonen\",\n",
    "            \"Analyse der Schutzfaktoren\",\n",
    "            \"Risiko-Matrix der Cluster\",\n",
    "            \"PCA-Visualisierung der Cluster\",\n",
    "            \"Profile der Sch√ºlergruppen\",\n",
    "            \"Radar-Chart der Risikoprofile\",\n",
    "            \"Motive: Wahrnehmung vs. T√§ter\",\n",
    "            \"Trendverlauf Gewaltformen\",\n",
    "            \"Trendverlauf Sicherheitsgef√ºhl\",\n",
    "            \"Wortwolke Feedback\"\n",
    "        ]\n",
    "        print(\"Verarbeite Bilder und f√ºge Titel hinzu...\")\n",
    "\n",
    "        for img_filename, desc in zip(images, descriptions):\n",
    "            img_path = os.path.join('img', img_filename)\n",
    "            if os.path.exists(img_path):\n",
    "\n",
    "                # 1. Originalbild √∂ffnen\n",
    "                original_image = Image.open(img_path)\n",
    "                orig_w, orig_h = original_image.size\n",
    "\n",
    "                # 2. Schriftart definieren\n",
    "                # Wir versuchen eine Standardschriftart von Linux/Colab zu laden, sieht besser aus.\n",
    "                try:\n",
    "                    font_path = \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"\n",
    "                    font_size = 24\n",
    "                    font = ImageFont.truetype(font_path, font_size)\n",
    "                except IOError:\n",
    "                    # Fallback, falls die Schriftdatei nicht existiert\n",
    "                    font = ImageFont.load_default()\n",
    "\n",
    "                # 3. Textgr√∂√üe berechnen (FIX f√ºr den AttributeError)\n",
    "                # Wir brauchen ein tempor√§res Draw-Objekt f√ºr die Berechnung\n",
    "                dummy_draw = ImageDraw.Draw(original_image)\n",
    "                # textbbox liefert (left, top, right, bottom)\n",
    "                bbox = dummy_draw.textbbox((0, 0), desc, font=font)\n",
    "                text_width = bbox[2] - bbox[0]\n",
    "                text_height = bbox[3] - bbox[1]\n",
    "\n",
    "                # Polsterung um den Text (oben und unten im neuen Bereich)\n",
    "                padding_y = 20\n",
    "                textbox_height = text_height + (padding_y * 2)\n",
    "\n",
    "                # Neue Gesamth√∂he berechnen\n",
    "                new_h = orig_h + textbox_height\n",
    "\n",
    "                # 4. Neues, gr√∂√üeres, wei√ües Bild erstellen\n",
    "                new_image = Image.new('RGB', (orig_w, new_h), color='white')\n",
    "\n",
    "                # 5. Originalbild oben einf√ºgen\n",
    "                new_image.paste(original_image, (0, 0))\n",
    "\n",
    "                # 6. Text auf den unteren wei√üen Bereich zeichnen\n",
    "                draw_final = ImageDraw.Draw(new_image)\n",
    "\n",
    "                # X-Position zentriert\n",
    "                text_x = (orig_w - text_width) / 2\n",
    "                # Y-Position: Unterhalb des Originalbilds + Polsterung\n",
    "                text_y = orig_h + padding_y\n",
    "\n",
    "                # Text in Schwarz zeichnen\n",
    "                draw_final.text((text_x, text_y), desc, font=font, fill=\"black\")\n",
    "\n",
    "                # 7. Das modifizierte Bild speichern (√ºberschreibt das alte)\n",
    "                new_image.save(img_path)\n",
    "\n",
    "        if confirm.lower() == 'j':\n",
    "            from google.colab import files\n",
    "            zip_name = f'Auswertung_Bilder_{safe_school_year}'\n",
    "            zip_filename = f'{zip_name}.zip'\n",
    "\n",
    "            print(f\"Erstelle ZIP-Datei: {zip_filename}...\")\n",
    "            shutil.make_archive(zip_name, 'zip', 'img')\n",
    "\n",
    "            print(f\"Starte Download von {zip_filename}...\")\n",
    "            files.download(zip_filename)\n",
    "        else:\n",
    "             print(\"Download abgebrochen. Die Bilder mit Titeln liegen im Ordner 'img'.\")\n",
    "else:\n",
    "    print(\"Dieser Code ist f√ºr Google Colab optimiert. Die Bilder wurden (falls vorhanden) im Ordner 'img' gespeichert, aber nicht modifiziert oder heruntergeladen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
